"""
The kaiten scheduler, which is currently two objects for legacy reasons.
"""

import datetime
import select
import heapq

import kaiten.log

# TODO: this is stupid
def get_storage_key(io_generator):
    try:
        return io_generator.key
    except AttributeError:
        return io_generator.connection.fileno()

class IOPollGenerator(object):
    """
    A Generator for IO poll events.
    """
    def __init__(self, error_callback):
        self._log = kaiten.log.getlogger(self)
        # {unique_key: [io_generator, ...]}
        self._io_generators = {}
        self._timeout = None
        self._poll = select.poll()
        self._error_callback = error_callback
        # Map poll errors to appropriate IOErrors
        self._error_poll_events = {
            select.POLLERR : IOError(5, 'EIO', 'Poll raised POLLERR'),
            select.POLLHUP : IOError(19, 'ENODEV', 'Poll raised POLLHUP'),
            select.POLLNVAL : IOError(19, 'ENODEV', 'Poll raised POLLNVAL'),
        }
        self._error_mask = sum(self._error_poll_events)
        self._generator = self._run()
        self._profiler = None

    def set_profiler(self, profiler):
        """
        Install a profiler, or clear it if passed None.
        """
        self._profiler = profiler

    def _eventmask(self, key):
        eventmask = 0

        for generator in self._io_generators[key]:
            if generator.is_reader():
                eventmask |= select.POLLIN
            if generator.is_writer():
                eventmask |= select.POLLOUT
            for error_poll in self._error_poll_events:
                eventmask |= error_poll

        return eventmask

    def update_eventmask(self, io_generator):
        """
        Updates the event mask for the connection for io_generator
        """
        key = get_storage_key(io_generator)

        if key not in self._io_generators:
            return

        self._poll.modify(key, self._eventmask(key))

    def register(self, io_generator):
        """
        Registers an IO generator. IO generators must be iterable, and must
        provide the methods fileno(), is_reader() and is_writer()

        @param io: IO generator
        """
        key = get_storage_key(io_generator)
        if key not in self._io_generators:
            self._io_generators[key] = []

        self._io_generators[key].append(io_generator)
        self._poll.register(key, self._eventmask(key))

    def unregister(self, dead_generator):
        """
        Unregister an IO generator

        @param dead: generator to be removed
        """
        key = get_storage_key(dead_generator)

        if key not in self._io_generators:
            return

        if dead_generator not in self._io_generators[key]:
            return

        self._io_generators[key].remove(dead_generator)

        if len(self._io_generators[key]) == 0:
            self._io_generators.pop(key)
            self._poll.unregister(key)
        else:
            self._poll.modify(key, self._eventmask(key))

    def unregister_all(self, connection=None, key=None):
        """
        Unregister all generators attached to a specific connection.

        @param connection: socket connection or connection for a registered
          generator
        """
        if key is None:
            key = connection.fileno()

        if key not in self._io_generators:
            return

        self._io_generators.pop(key)
        self._poll.unregister(key)

    def _set_timeout(self, timeout):
        """
        Set the timeout for the next iteration.

        @param timeout: Duration of the timeout in milliseconds.
          Set it to 0 to not block, None to block indefinitely.
          Also accepts positive datetime.timedelta objects.
        """
        if isinstance(timeout, datetime.timedelta):
            # This does not handle negative timedeltas or timedeltas
            # greater than one day, but it is measurably faster than
            # int(timeout.total_seconds()*1000) due to the lack of
            # floating point math.
            timeout = timeout.seconds * 1000 + timeout.microseconds // 1000
        self._timeout = timeout

    def _run(self):
        """
        Generator method for iterating IO generators.  Blocks on the poll set for
        the specified timout time, and iterates any generators who's filehandles
        have events.
        """
        while True:
            try:
                events = self._poll.poll(self._timeout)
            except InterruptedError:
                yield
            if len(events) == 0:
                yield
            else:
                if self._profiler: self._profiler.tick()
                yield from self._handle_events(events)

    def iter_with_timeout(self, timeout):
        """
        Service exactly one IOGenerator with a pending event, blocking
        for at least the specified timeout if no events are pending.

        @param timeout: Duration of the timeout in milliseconds.
          Set it to 0 to not block, None to block indefinitely.
          Also accepts positive datetime.timedelta objects.
        """
        self._set_timeout(timeout)
        next(self._generator)

    def _io_generator_next(self, io_generator):
        if self._profiler:
            self._profiler.log_io_generator(io_generator)
        try:
            next(io_generator)
        except StopIteration as e:
            self.unregister(io_generator)
        except Exception as e:
            self._error_callback(io_generator, e)

    def _handle_events(self, events):
        yielded = False
        for (fileno, event) in events:
            # Sometimes one generator we run from this loop can unregister all
            # of the generators for a connection that is also scheduled in
            # events, so fileno may not actually be in self._io_generators
            if fileno not in self._io_generators: continue

            writing = event & select.POLLOUT
            reading = event & select.POLLIN

            # This will iterate for each generator that is registered to this
            # filenumber.  Generators are added via the "register" function
            for io_generator in self._io_generators[fileno][:]:
                if event & self._error_mask:
                    # Choose any single flag that is set to report
                    io_err_map = self._error_poll_events
                    io_err = next(v for k, v in io_err_map.items() if k & event)
                    self._error_callback(io_generator, io_err)
                    # Generally we let _error_callback decide what to
                    # unregister, but we absolutely have to unregister
                    # here or we get stuck in an infinite loop.
                    self.unregister_all(key=fileno)
                else:
                    # NB: The following is a GUIDELINE, not a rule
                    # Write operations are often calling next on the
                    # GeneratorQueue for a specific jsonrpc.  Check there
                    # for more information.
                    if writing and io_generator.is_writer():
                        self._io_generator_next(io_generator)
                        yield
                        yielded = True
                    # NB: The following is a GUIDELINE, not a rule
                    # JsonRPC objects are mainly the only reader objects
                    elif reading and io_generator.is_reader():
                        self._io_generator_next(io_generator)
                        yield
                        yielded = True
        if not yielded:
            yield


class Contract(object):
    def __init__(self, id, generator):
        self.id = id
        self.generator = generator
        self.reschedule()

    def reschedule(self):
        now = datetime.datetime.utcnow()
        self.next_run = now + self.generator.contract_duration()

    # Stupid rich comparison...
    def __lt__(self, other): return self.next_run <  other.next_run
    def __gt__(self, other): return self.next_run >  other.next_run
    def __le__(self, other): return self.next_run <= other.next_run
    def __ge__(self, other): return self.next_run >= other.next_run
    def __eq__(self, other): return self.next_run == other.next_run
    def __ne__(self, other): return self.next_run != other.next_run


class ContractQueue(object):
    """ Priority queue!!! """
    def __init__(self):
        self._queue = []

    def add_contract(self, id, generator):
        contract = Contract(id, generator)
        self.insert(contract)

    def insert(self, contract):
        heapq.heappush(self._queue, contract)

    def root(self):
        """ Return the next contract due """
        return self._queue[0]

    def reschedule_root(self):
        root = self._queue[0]
        root.reschedule()
        heapq.heapreplace(self._queue, root)

    def remove(self, id):
        # At no point should we rely on testing equality with
        # elements of _queue, since they implement rich comparison
        for idx in range(len(self._queue)):
            if self._queue[idx].id == id:
                # heapq doesn't directly expose anything helpful here
                last = self._queue.pop()
                if idx >= len(self._queue):
                    return last
                ret = self._queue[idx]
                self._queue[idx] = last
                # Fuck it, this will work and we only ever have
                # like a dozen elements in the queue
                heapq.heapify(self._queue)
                return ret
        raise KeyError('no such contract')


class ContractGeneratorManager(object):
    """
    Manages two classes of generators, contract generators that do non-io
    work, and must be run on some interval, and one blocking generator
    that can block for a specific amount of time.  This is not itself a
    generator -- a call to run() will not return until some generator
    managed here (or another thread or a signal handler) invokes stop()

    The blocking generator must be an IOPollGenerator instance.
    """

    def __init__(self, blocking):
        self._log = kaiten.log.getlogger(self)
        self._contracts = ContractQueue()
        self._blocking = blocking
        self._stop = False
        self._profiler = None

    def set_profiler(self, profiler):
        """
        Install a profiler for this scheduler, or clear it if passed None.
        """
        self._profiler = profiler
        self._blocking.set_profiler(profiler)

    def stop(self):
        # This must remain thread and signal safe!!!
        self._stop = True

    def add_contract_generator(self, contract_generator, id=None):
        """
        Adds a new contract generator.

        @param contract_generator: Generator to be added, must support
            contract_duration() and return a timedelta
        @param id object used to look up this generator when calling evict
            et al.  Lookup uses "is", so a copy of the object will not suffice.
        """
        if None is id:
            id = contract_generator
        self._contracts.add_contract(id, contract_generator)

    def reschedule_contract_generator(self, id):
        """
        Reschedules an already listed a contract generator.  Generally a good
        idea whenever the contract duration changes significantly.
        @param contract_generator: generator to be rescheduled
        """
        try:
            contract = self._contracts.remove(id)
            contract.reschedule()
            self._contracts.insert(contract)
        except KeyError as e:
            self._log.info("Contract %s not in list of contracts" % (id))

    def evict_contract_generator(self, id):
        """
        Evicts a contract generator from the list
        @param contract_generator: generator to be evicted
        """
        try:
            self._contracts.remove(id)
        except KeyError as e:
            self._log.info("Contract %s not in list of contracts" % (id))

    def run(self):
        """
        Iteration.  Bounces between contract generators who's time is due and
        the blocking generator when we have time to the next contract.
        """
        while not self._stop:
            now = datetime.datetime.utcnow()
            if self._profiler: self._profiler.tick(now)
            try:
                contract = self._contracts.root()
            except IndexError:
                # No contracts, block indefinitely
                self._blocking.iter_with_timeout(None)
                continue
            if contract.next_run > now:
                # Block until contract is up
                self._blocking.iter_with_timeout(contract.next_run - now)
                continue
            self._contracts.reschedule_root()
            if self._profiler: self._profiler.log_contract(contract.id)
            try:
                next(contract.generator)
            except StopIteration:
                self.evict_contract_generator(contract.id)
            except Exception:
                self._log.error(
                    'Evicting %s due to unhandled exception',
                    contract.id.__class__.__name__, exc_info=True)
                self.evict_contract_generator(contract.id)
            if self._profiler: self._profiler.tick()
            # do a non-blocking io iterate to make sure a long
            # contract doesn't starve io
            self._blocking.iter_with_timeout(0)

