import sys
import logging
import datetime
import json
import os

import kaiten.client
import kaiten.constants
import kaiten.decorator
import kaiten.error

from kaiten.processes.process import Process

def _make_process_method_during(callable, steps):
    """
    utility method to set functionattributes for an already-defined function
    to be a process method.
    @param callable callable. Method to decorate
    @param steps list of steps, as strings, to be available in.
    """
    setattr(callable, kaiten.decorator.FunctionAttributes.process_method,
            True)
    current_steps = set(getattr(callable,
                            kaiten.decorator.FunctionAttributes.available_during,
                            []))
    current_steps |= set(steps)
    setattr(callable, kaiten.decorator.FunctionAttributes.available_during,
            [s for s in current_steps])


class SetupMetaProcess(Process):
    """
    A subclass of Process for wrapping a subprocess up with the steps needed
    for SetupProcess (like the intro screens, etc) into lumps to save a bit
    of complexity in SetupProcess itself.

    It also contains logic for things that most setup metaprocesses will
    probably want, like waiting for a continue in a consistent fashion.

    To ensure the process methods are properly registered, do not call this
    __init__() method until all process methods are registered.

    Note: subclasses MUST add a list of all their steps + any subprocess steps
    to self.steps after calling super().__init__(), this is required for the
    skip() and back() logic to work.
    """
    def __init__(self, machine_manager, pymach, config,
                 name='SetupProcess', steps=[]):
        steps.append("metadone")
        super().__init__(machine_manager, pymach, config, name, steps)
        self._waiting_for_continue = False
        self._next_step = None
        self.cancellable_toolhead_errors = set()
        machine_manager.clear_toolhead_error_memory()

    def update_process_methods(self, new):
        """ A recursive method for updating process method dicts. This prevents
        subprocess reloads from overwriting the references that setupprocess
        relies on for some reason.
        """
        self.update_dict(self._process_methods, new)

    @staticmethod
    def update_dict(old, new):
        for key in new:
            if key in old:
                if type(new[key]) is dict:
                    SetupMetaProcess.update_dict(old[key], new[key])
                else:
                    old[key] = new[key]
            else:
                old[key] = new[key]

    @staticmethod
    def settings_key(self):
        """ This method should be overriden by child processes to return what their
        name in a settings file should be.
        """
        raise NotImplementedError

    def back_init(self):
        """
        back init logic that is ran a metaprocess is called from a process ahead of it
        only implemented when one does not wish to start the process at init
        see WelcomeScreenMetaprocess for example
        """
        pass

    def _wait_for_continue(self):
        """A private method to use when waiting for a continue()
        process_method"""

        self._waiting_for_continue = True
        while self._waiting_for_continue:
            yield

    def all_steps(self):
        """ return the steps of the process and any subprocesses """
        return self.steps

    def retry_steps(self):
        """Subclasses should implement this method to return a list of steps
        where the retry option should be available.
        By default this will retry error step if it exists"""
        retry_list = []
        if self.error_step() is not None:
            retry_list.append(self.error_step())
        return retry_list

    def handle_skip(self):
        """ This method may be overridden by subclasses to provide cancel
        steps for skip. It should be a generator.
        """
        self.cancel()
        yield from self.tasklets

    def handle_back(self):
        """ This method may be overridden by subclasses to provide handling or
        cancel steps for moving back. It should be a generator.
        The provided implementation is the most common case for metaprocesses with
        subprocesses and an intro step.

        If returns True, metaprocess will remain current metaprocess
        If returns False, first previous metaprocess w/ should_run==True is run. """
        if self.step == self.intro_step():
            self.cancel()
            yield from self.tasklets
            return False
        else:
            yield from self._cancel_subprocess()
            self._step_change(self.steps.running)
            self.continue_process()
            return True

    def handle_error(self, error_dict):
        """ A default handle_error for metaprocesses with subprocesses that
        passes the error on to the subprocess if it's running.
        """
        if None is not self.subprocess_step():
            response = self.subprocess_process().handle_error(error_dict)
            sev = self._machine_manager._assess_machine_error_severity(error_dict['code'])
            if (error_dict['code']\
               in self.subprocess_process().cancellable_toolhead_errors)\
               or (sev == self._machine_manager._error_severity.process_critical):
                # The subprocess can't handle this error and is expecting
                # machine manager to cancel it - let's oblige it
                self.subprocess_process().cancel()
                self._set_tasklets(self._subprocess_cleanup())
                #redirect toolhead errors to the load_print_tool metaprocess
            if error_dict['code'] == kaiten.error.no_tool_connected:
                self._next_step = "load_print_tool"
                response = True
            elif error_dict['code'] == kaiten.error.tool_not_calibrated:
                self._next_step = 'z_calibration'
                response = True
            elif error_dict['code'] == kaiten.error.no_filament:
                self._next_step = "load_filament"
                response = True
            else:
                self._log.warning("error {0} not handled by setupmetaprocess"\
                                  .format(error_dict['code']))
            return response
        else:
            return True

    def next_step(self):
        """ used to skip to a metaprocessess that isn't directly after this one
        return None to go to next, or settings_key of metaprocess to skip to"""
        return self._next_step

    def _step_change(self, step, error_dict=None):
        """
        Override Implementation for analytics purposes
        """
        if step != self.step:
            super()._step_change(step, error_dict)
            if  step != "cancelling" and\
                step != "cleaning_up" and\
                step != "metadone":
                self._machine_manager._server.mixpanel_event("fre",
                    self._machine_manager.process_method_client(),
                    step=step, action="reached")

    def _get_ignorable_toolhead_errors(self):
        """ Trust the subprocess for what to ignore """
        if None is not self.subprocess_step():
            return self.subprocess_process().ignorable_toolhead_errors
        else:
            return set(kaiten.error.toolhead_errors)

    def _get_cancellable_toolhead_errors(self):
        """ Nothing is allowed to cancel us but a user action. """
        return set()

    def continue_process(self):
        """A method for use as a private method to continue"""
        self._waiting_for_continue = False

    def override_watchdog_status(self):
        """A method for returning the override heater watchdog status of a metaprocess"""
        if None is not self.subprocess_step():
            return self.subprocess_process().overrides_heater_watchdog
        else:
            return False

    def get_info_dict(self):
        """ A unified way for SetupProcess to get both the current metaproc step
        and information from a subprocess (if it exists)
        """
        spi = self.subprocess_info()
        info = {'setup_step': self.step}
        if spi:
            info.update(spi)
        else:
            info.update(super().get_info_dict())
        return info

    def cleanup(self):
        """
        This overrides Process's implementation so it can prevent a step_change to done/cleaning_up
        """
        self._cancellable = False
        self._step_change(self.steps.cleaning_up)
        yield from self._do_cleanup()
        self._step_change(self.steps.metadone)

    def cancel(self, error_dict=None):
        """
        Override required here because we must cancel our subprocess before the metaprocess
        or else printerpanel doesn't recieve the propper clean up notifications
        """
        self.tasklets = self._cancel_metaprocess(error_dict)

    def _cancel_metaprocess(self, error_dict=None):
        if None is not self.subprocess_process() and self.step != self.intro_step():
            yield from self._cancel_subprocess()
        self.cancelled = True
        if error_dict:
            self.failed = True
        self._cancellable = False
        self._step_change(self.steps.cancelling, error_dict)
        yield from self._cancel(error_dict)

    def _cancel_subprocess(self, error_dict=None):
        if None is not self.subprocess_process() and self.subprocess_process().step != "done":
            self.subprocess_process().cancel(error_dict)
            yield from self.subprocess_process().tasklets

    def is_cancellable(self):
        process = self.subprocess_process()
        return process is None or process.is_cancellable()

    def subprocess_info(self):
        """ A method for child classes to implement to return info dicts for
        the currently running subprocess. This implementation should return
        {} or None if no subprocess is currently running.
        """
        return None

    def subprocess_step(self):
        """ A method for child classes to implement to return the current step
        of its subprocess. Should be step name or None. Helps with dispatch of
        process methods."""
        return None

    def intro_step(self):
        """ A method for child classes to implement to return the intro step.
        Should be step name or None."""
        return None

    def complete_step(self):
        """ A method for child classes to implement to return the complete step.
        Should be step name or None."""
        return None

    def error_step(self):
        """ A method for child classes to implement to return the error step.
        Should be step name or None."""
        return None

    def process_step(self):
        """ A method for child classes to implement to return the process step.
        Should be step name or None."""
        return None

    def subprocess_process(self):
        """ A method for child classes to implement to return the process of a
         subprocess. Should be the process or None. Helps with dispatch of
        process methods."""
        return None

    def should_run(self):
        """
        Logic that determines whether or not a metaprocess should run
        """
        return True

    def back(self):
        """
        Logic that runs whenever back is called while this metaprocess is the
         current metaprocess.

        If True is returned, this process will no longer be the current_metaprocess
        """
        return True

    def contract_duration(self):
        """
        Superclass Implementation
        """
        return datetime.timedelta(0, 0, 0, 5)


    def _do_initialize(self):
        """
        This overrides Process's implementation so a metaprocess will be skipped
        if it should not run
        """
        if not self.should_run():
            self.cancel()
        yield kaiten.error.ok

    def _init_process(self):
        """
        this function must be overriden by any metaprocess that wishes to
        utilize the beautiful default implementations
        """
        raise NotImplementedError

    def _do_run(self):
        """This is the most common run implementation for metaprocesses
        with subprocesses. This must be overwritten by any metaprocesses that
        do not have a subprocess or require special logic."""
        if self.intro_step() is None or self.complete_step() is None or self.process_step()\
            is None or self.error_step() is None:
            #prevent stupid mistakes by ensuring anyone using this implements these steps
            raise NotImplementedError
        isDone = False
        while not isDone:
            if self.step == self.steps.running:
                self._step_change(self.intro_step())
                yield from self._wait_for_continue()
            elif self.step == self.intro_step():
                self._init_process()
                self._step_change(self.process_step())
                processDone = False
                while not processDone:
                    try:
                        yield next(self.subprocess_process().tasklets)
                    except StopIteration:
                        processDone = True
            elif self.step == self.process_step():
                if self.subprocess_process().complete:
                    self._step_change(self.complete_step())
                    yield from self._wait_for_continue()
                elif self.subprocess_process().cancelled:
                    self._step_change(self.steps.running)
                else:
                    self._step_change(self.error_step())
                    yield from self._wait_for_continue()
                if(self.step != self.steps.running):
                    isDone = True
            else:
                # Hey lets maybe not loop forever in this case
                raise Exception('Unexpected step ' + str(self.step))

    def _callable_methods(self):
        sps = self.subprocess_step()
        step = sps
        if not step:
            step = self.step
        if step in self._process_methods:
            return self._process_methods[step]
        else:
            return {}

    def _subprocess_cleanup(self):
        """ used to iterate through a subprocess after it has been cancelled """
        processDone = False
        while not processDone:
            try:
                yield next(self.subprocess_process().tasklets)
            except StopIteration:
                processDone = True
        self._restore_tasklets()

    def _set_tasklets(self, generator):
        self._stored_tasklets = self.tasklets
        self.tasklets = generator

    def _restore_tasklets(self):
        self.tasklets = self._stored_tasklets

class WelcomeScreenMetaprocess(SetupMetaProcess):
    """ A simple metaprocess that sets dummy steps so connected clients can
    display welcome screens.
    """
    def __init__(self, machine_manager, pymach, config):
        steps = ['welcome_panel_knob',
                 'welcome_panel_buttons', 'welcome_panel_download_app']
        _make_process_method_during(SetupMetaProcess.continue_process,
                                    steps)
        super().__init__(machine_manager, pymach, config, steps=steps)

    def handle_back(self):
        yield
        if(self.step == self.steps.welcome_panel_download_app):
            #if on download_app, go to buttons
            self.step = self.steps.welcome_panel_knob
            self.continue_process();
        else:
            #if on buttons or knob, go to knob
            self.step = self.steps.running
            self.continue_process();
        #dont go anywhere
        return True

    @staticmethod
    def settings_key():
        return "welcome_screen"

    def back_init(self):
        """
        start metaprocess off at welcome_panel_download_app if going back from future metaprocess
        this requires a special _do_run implementation such as the the while loop implemetation
        that this process uses
        """
        self.step = self.steps.welcome_panel_buttons

    def retry_steps(self):
        """ this process displays some screens, retrying is meaningless """
        return []

    def _do_run(self):
        isDone = False
        while not isDone:
            if self.step == self.steps.running:
                self._step_change(self.steps.welcome_panel_knob)
                yield from self._wait_for_continue()
            elif self.step == self.steps.welcome_panel_knob:
                self._step_change(self.steps.welcome_panel_buttons)
                yield from self._wait_for_continue()
            elif self.step == self.steps.welcome_panel_buttons:
                self._step_change(self.steps.welcome_panel_download_app)
                yield from self._wait_for_continue()
                #this if is required to ensure a back wasn't called
                if(self.step == self.steps.welcome_panel_download_app):
                    isDone = True
            else:
                # Hey lets maybe not loop forever in this case
                raise Exception('Unexpected step ' + str(self.step))

class EndMetaprocess(SetupMetaProcess):
    """ A simple metaprocess that sets dummy steps so connected clients can
    display welcome screens.
    """
    def __init__(self, machine_manager, pymach, config):
        step = 'setup_complete'
        _make_process_method_during(SetupMetaProcess.continue_process,
                                    [step])
        super().__init__(machine_manager, pymach, config, steps=[step])

    def handle_back(self):
        yield
        # we never can't go back from here
        return False

    @staticmethod
    def settings_key():
        return "end"

    def _do_run(self):
        self._step_change(self.steps.setup_complete)
        yield from self._wait_for_continue()

class LoadPrintToolMetaprocess(SetupMetaProcess):
    """ A metaprocess for loading print tool - honestly, loading print tool
    should probably have a bit more structure in the first place
    """
    def __init__(self, machine_manager, pymach, config):
        steps = ["loading_print_tool_intro",
                 "loading_print_tool",
                 "loading_print_tool_complete",
                 "loading_print_tool_error"]
        _make_process_method_during(SetupMetaProcess.continue_process,
                                    ["loading_print_tool_intro",
                                     "loading_print_tool_complete",
                                     "loading_print_tool_error"])
        super().__init__(machine_manager, pymach, config, steps=steps)

    @staticmethod
    def settings_key():
        return "load_print_tool"

    def handle_error(self, error_dict):
        """ load_print_tool requires its own handle_error implementation
            because it does not have a subprocess like typical metaprocesses
        """
        self._log.info("in LoadPrintToolMetaprocess handle_error for {0}".format(error_dict))
        return True

    def should_run(self):
        """
        This overrides SetupMetaProcess's implementation so we will only run
        this metaprocess when a tool is not connected
        """
        return not self._pymach.is_tool_connected(0)

    def handle_back(self):
        if self.step in [self.steps.loading_print_tool,
                         self.steps.loading_print_tool_complete,
                         self.steps.loading_print_tool_error]:
            yield from self._pymach.abort()
        else:
            yield
        if self.step == self.steps.loading_print_tool_intro:
            return False
        else:
            self.step = self.steps.running
            self.continue_process()
            return True

    def _do_run(self):
        isDone = False
        while not isDone:
            if self.step == self.steps.running:
                self._step_change(self.steps.loading_print_tool_intro)
                yield from self._wait_for_continue()
            elif self.step == self.steps.loading_print_tool_intro:
                self._step_change(self.steps.loading_print_tool)
                yield from self._pymach.connect_tool(0, abort_toolhead_only=False)
            elif self.step == self.steps.loading_print_tool:
                if self._pymach.is_tool_connected(0):
                    self._step_change(self.steps.loading_print_tool_complete)
                    yield from self._wait_for_continue()
                else:
                    self._step_change(self.steps.loading_print_tool_error)
                    yield from self._wait_for_continue()
                if(self.step != self.steps.running):
                    isDone = True
            else:
                # Hey lets maybe not loop forever in this case
                raise Exception('Unexpected step ' + str(self.step))

    def intro_step(self):
        return self.steps.loading_print_tool_intro

    def error_step(self):
        return self.steps.loading_print_tool_error

    def complete_step(self):
        return self.steps.loading_print_tool_complete

class AssistedLevelingMetaprocess(SetupMetaProcess):
    """ A metaprocess for doing leveling """
    def __init__(self, machine_manager, pymach, config):
        _make_process_method_during(SetupMetaProcess.continue_process,
                            ["assisted_leveling_intro",
                             "assisted_leveling_complete",
                             "assisted_leveling_error"])
        steps = ['assisted_leveling_intro',
                 'assisted_leveling',
                 'assisted_leveling_complete',
                 'assisted_leveling_error']
        super().__init__(machine_manager, pymach, config, steps=steps)
        self._init_process()
        self.steps.extend(*[s for s in self._level_process._assisted_level_steps])

    def _init_process(self):
        self._level_process\
            = kaiten.processes.AssistedLevelingProcess(self._machine_manager, self._pymach,
            self._config)
        self._subprocess_methods = self._level_process._process_methods
        self.update_process_methods(self._subprocess_methods)
        self._machine_manager.clear_toolhead_error_memory()

    @staticmethod
    def settings_key():
        return "assisted_leveling"

    def intro_step(self):
        return self.steps.assisted_leveling_intro

    def error_step(self):
        return self.steps.assisted_leveling_error

    def complete_step(self):
        return self.steps.assisted_leveling_complete

    def process_step(self):
        return self.steps.assisted_leveling

    def subprocess_step(self):
        if self.step == self.steps.assisted_leveling:
            return self._level_process.step
        else:
            return None

    def subprocess_info(self):
        if self.step == self.steps.assisted_leveling:
            return self._level_process.get_info_dict()
        else:
            return None

    def subprocess_process(self):
        return self._level_process

class LoadFilamentMetaprocess(SetupMetaProcess):
    """ put the filament in the snout """
    def __init__(self, machine_manager, pymach, config):
        _make_process_method_during(SetupMetaProcess.continue_process,
                                    ['load_filament_intro',
                                     'load_filament_complete',
                                     'load_filament_timeout',
                                     'load_filament_error'])
        steps = ['load_filament_intro',
                 'load_filament',
                 'load_filament_complete',
                 'load_filament_timeout',
                 'load_filament_error']
        super().__init__(machine_manager, pymach, config, steps=steps)
        self._load_filament_process = None
        self._subprocess_methods = {'extrusion': {'stop_filament': self.stop_filament}}
        self._init_process()
        self.steps.extend(*[s
                            for s
                            in self._load_filament_process._load_filament_steps])
        self.stop_filament_flag = False

    def _init_process(self):
        self._load_filament_process\
            = kaiten.processes.LoadFilamentProcess(self._machine_manager, self._pymach, 0, self._config)
        self.update_process_methods(self._subprocess_methods)
        self._machine_manager.clear_toolhead_error_memory()

    @staticmethod
    def settings_key():
        return "load_filament"

    def should_run(self):
        """
        This overrides SetupMetaProcess's implementation so we will only run
        this metaprocess when a tool is not connected
        """
        return not self._pymach.get_filament_presence(0)

    def stop_filament(self, error_dict=None):
        self.stop_filament_flag = True
        self._load_filament_process.stop_filament()

    def retry_steps(self):
        return [self.steps.load_filament_error,
                self.steps.load_filament_timeout]

    def _do_run(self):
        self.stop_filament_flag = False
        isDone = False
        while not isDone:
            if self.step == self.steps.running:
                self._step_change(self.steps.load_filament_intro)
                yield from self._wait_for_continue()
            elif self.step == self.steps.load_filament_intro:
                self._init_process()
                self._step_change(self.steps.load_filament)
                processDone = False
                while not processDone:
                    try:
                        next(self._load_filament_process.tasklets)
                        yield
                    except StopIteration:
                        processDone = True
            elif self.step == self.steps.load_filament:
                if self.stop_filament_flag:
                    self.stop_filament_flag = False
                    self._step_change(self.steps.load_filament_complete)
                    yield from self._wait_for_continue()
                elif self._load_filament_process.cancelled:
                    self._step_change(self.steps.running)
                elif self._load_filament_process._error:
                    self._step_change(self.steps.load_filament_error)
                    yield from self._wait_for_continue()
                else:
                    self._step_change(self.steps.load_filament_timeout)
                    yield from self._wait_for_continue()
                if(self.step != self.steps.running):
                    isDone = True
            else:
                # Hey lets maybe not loop forever in this case
                raise Exception('Unexpected step ' + str(self.step))

    def subprocess_info(self):
        if self.step == self.steps.load_filament:
            return self._load_filament_process.get_info_dict()
        else:
            return None

    def intro_step(self):
        return self.steps.load_filament_intro

    def error_step(self):
        return self.steps.load_filament_error

    def complete_step(self):
        return self.steps.load_filament_complete

    def process_step(self):
        return self.steps.load_filament

    def subprocess_step(self):
        if self.step == self.steps.load_filament:
            return self._load_filament_process.step
        else:
            return None

    def subprocess_process(self):
        return self._load_filament_process

    def handle_error(self, error_dict):
        """ Override for LoadFilamentMetaprocess that handles out of filament"""
        if error_dict['code'] == kaiten.error.no_filament:
            if None is not self.subprocess_step():
                return self._load_filament_process.handle_error(error_dict)
            else:
                return True
        else:
            return super().handle_error(error_dict)

    def _do_cancel(self, error_dict=None):
        """ LoadFilamentMetaprocess override to cool correctly"""
        yield from self._pymach.cool()

class ZCalibrationMetaprocess(SetupMetaProcess):
    """ A metaprocess for doing whatever type of calibration the machine
    requires.
    """
    def __init__(self, machine_manager, pymach, config):
        _make_process_method_during(SetupMetaProcess.continue_process,
                                    ["z_calibration_intro",
                                     "z_calibration_complete",
                                     "z_calibration_error"])
        steps = ["z_calibration_intro",
                 "z_calibration",
                 "z_calibration_complete",
                 "z_calibration_error"]
        super().__init__(machine_manager, pymach, config, steps=steps)
        self._init_process()
        self.steps.extend(*[s for s in self._zcal_process._zcal_steps])

    def _init_process(self):
        self._zcal_process\
            = kaiten.processes.ZCalibrationProcess(self._machine_manager, self._pymach,
            self._config)
        self._subprocess_methods = self._zcal_process._process_methods
        self.update_process_methods(self._subprocess_methods)
        self._machine_manager.clear_toolhead_error_memory()

    @staticmethod
    def settings_key():
        return "z_calibration"

    def intro_step(self):
        return self.steps.z_calibration_intro

    def error_step(self):
        return self.steps.z_calibration_error

    def complete_step(self):
        return self.steps.z_calibration_complete

    def process_step(self):
        return self.steps.z_calibration

    def subprocess_step(self):
        if self.step == self.steps.z_calibration:
            return self._zcal_process.step
        else:
            return None

    def subprocess_info(self):
        if self.step == self.steps.z_calibration:
            return self._zcal_process.get_info_dict()
        else:
            return None

    def subprocess_process(self):
        return self._zcal_process

class WifiSetupMetaprocess(SetupMetaProcess):
    """ A metaprocess for running wifi configuration. """
    def __init__(self, machine_manager, pymach, config):
        _make_process_method_during(SetupMetaProcess.continue_process,
                                ['wifi_setup_intro', 'wifi_setup_ethernet_connected'])
        steps = ['wifi_setup_intro',
                 'wifi_setup_ethernet_connected',
                 'wifi_setup']
        super().__init__(machine_manager, pymach, config, steps=steps)
        self._init_process()
        self.steps.extend(*[s for s in kaiten.processes.WifiSetupProcess._wifi_steps])
        self._skip_intro = False

    def handle_skip(self):
        """ WifiSetupMetaProcess implementation. Does not end the tether when
        cancelling the subprocess.
        """
        if self.step == self.steps.wifi_setup_intro:
            """We want to begin tethering before cancelling."""
            yield from self._machine_manager._server.dbus_manager.ensure_tether(True)
        self.cancel(keep_tether=True)
        yield from self.tasklets

    def cancel(self, error_dict=None, keep_tether=False):
        self.tasklets = self._cancel_metaprocess(error_dict, keep_tether)
        
    def _cancel_metaprocess(self, error_dict=None, keep_tether=False):
        if None is not self.subprocess_process() and self.step != self.intro_step():
            yield from self._cancel_subprocess(keep_tether=keep_tether)
        self.cancelled = True
        if error_dict:
            self.failed = True
        self._cancellable = False
        self._step_change(self.steps.cancelling, error_dict)
        yield from self._cancel(error_dict)

    def _cancel_subprocess(self, error_dict=None, keep_tether=False):
        if None is not self.subprocess_process()\
           and self.subprocess_process().step != "done":
            # If we are skipping, and if we're in a state where we're already
            # tethered, we can stay tethered - SetupProcess will untether us
            # later.
            # This is to allow users to not connect to wifi, but continue to
            # interact with the printer through their phone.
            self.subprocess_process().cancel(error_dict, keep_tether\
                                             and self.subprocess_step() in\
                                             [self.steps.configure,
                                              self.steps.connect_error])
            yield from self.subprocess_process().tasklets

    def _init_process(self):
        self._wifi_config_process \
            = kaiten.processes.WifiSetupProcess(self._machine_manager, self._pymach, self._config,
                                                self._machine_manager._server.dbus_manager)
        self.update_process_methods(self._wifi_config_process._process_methods)
        self._machine_manager.clear_toolhead_error_memory()

    def _ethernet_connected(self):
        """
        Returns True if ethernet is connected, False if not
        """
        state = self._machine_manager._server.network_state()
        if state.get('service_hash', '') == 'eth':
            return True
        return False

    def jump_to_wifi_setup(self):
        """
        Skips the intro step and goes straight to wifi tethering

        Does not work when the process is already running (really
        only intended to be used right after creating the process).
        """
        self._skip_intro = True

    def _do_run(self):
        isDone = False
        while not isDone:
            if self._ethernet_connected():
                self._step_change(self.steps.wifi_setup_ethernet_connected)
                yield from self._wait_for_continue()
                isDone = True
                continue
            if self._skip_intro and self.step == self.steps.running:
                self.step = self.steps.wifi_setup_intro
            if self.step == self.steps.running:
                self._step_change(self.steps.wifi_setup_intro)
                yield from self._wait_for_continue()
            elif self.step == self.steps.wifi_setup_intro:
                self._init_process()
                self._step_change(self.steps.wifi_setup)
                processDone = False
                while not processDone:
                    try:
                        yield next(self._wifi_config_process.tasklets)
                    except StopIteration:
                        processDone = True
            elif self.step == self.steps.wifi_setup:
                if self._wifi_config_process.cancelled:
                    self._step_change(self.steps.running)
                if(self.step != self.steps.running):
                    isDone = True
            else:
                # Hey lets maybe not loop forever in this case
                raise Exception('Unexpected step ' + str(self.step))
                yield

    @staticmethod
    def settings_key():
        return "wifi_setup"

    def handle_back(self):
        if self.step in (self.steps.wifi_setup_intro,
                         self.steps.wifi_setup_ethernet_connected):
            yield
            return False
        elif self.step == self.steps.wifi_setup:
            yield from self._cancel_subprocess()
            self._step_change(self.steps.running)
            return True
        else:
            yield from super().handle_back()


    def intro_step(self):
        return self.steps.wifi_setup_intro

    def process_step(self):
        return self.steps.wifi_setup

    def subprocess_step(self):
        if self.step == self.steps.wifi_setup\
           or (self.step == self.steps.cancelling\
               and self._wifi_config_process.step != self.steps.running):
            return self._wifi_config_process.step
        else:
            return None

    def subprocess_info(self):
        if self.step == self.steps.wifi_setup\
           or (self.step == self.steps.cancelling\
               and self._wifi_config_process.step != self.steps.running):
            return self._wifi_config_process.get_info_dict()
        else:
            return None

    def subprocess_process(self):
        return self._wifi_config_process

class FirmwareBurningMetaprocess(SetupMetaProcess):
    """ A metaprocess for running the firmware burning process. """
    def __init__(self, machine_manager, pymach, config):
        _make_process_method_during(SetupMetaProcess.continue_process,
            ['firmware_updates_checked'])

        steps = ['firmware_burning', 'firmware_checking_updates', 'firmware_updates_checked']
        self._firmware_process = None

        super().__init__(machine_manager, pymach, config, steps=steps)

        self.steps.extend(*[s for s in kaiten.processes.FirmwareBurningProcess._firmware_steps])

    def should_run(self):
        """
        If the connection went all right and firmware was available, we should
        know by now (and be mostly done downloading it, probably). If we don't
        already know a firmware update is ready, then either there isn't one or
        we're not connected. Either way we shouldn't run.
        """
        return self._machine_manager._server.firmware_updates.update_available

    def _init_process(self):
        self._firmware_process \
            = kaiten.processes.FirmwareBurningProcess(self._machine_manager,
                                                      self._pymach,
                                                      self._config,
                                                      firmware_updates=self._machine_manager._server.firmware_updates)
        self.update_process_methods(self._firmware_process._process_methods)
        self._machine_manager.clear_toolhead_error_memory()

    def _do_run(self):
        self._step_change(self.steps.firmware_checking_updates)
        self._machine_manager._server.firmware_updates.check()
        self._step_change(self.steps.firmware_updates_checked)
        yield from self._wait_for_continue()
        try:
            self._init_process()
            self._step_change(self.steps.firmware_burning);
            yield from self._firmware_process.tasklets
        except AttributeError as e:
            #We have no firmware update to do
            self._log.info("Failed to initialize FirmwareBurningProcess, continuing")
            yield

    def handle_skip(self):
        """
        overriding the setupmetaprocess implementation
        """
        if self._subprocess_step() and\
          self.subprocess_step() != self._firmware_process._firmware_steps.writing:
            self.cancel()
            yield from self.tasklets
        else:
            self.log.info("Can't cancel FirmwareBurningProcess during the writing step")
            yield

    def handle_back(self):
        if self.subprocess_step() and\
          self.subprocess_step() != self._firmware_process._firmware_steps.writing:
            self._firmware_process.cancel()
            yield from self._firmware_process.tasklets
        else:
            yield
        self.step = self.steps.running
        self.continue_process()
        return True

    @staticmethod
    def settings_key():
        return "firmware_burning"

    def intro_step(self):
        return None

    def process_step(self):
        return self.steps.firmware_burning

    def subprocess_step(self):
        if self._firmware_process and\
          self.step == self.steps.firmware_burning:
            return self._firmware_process.step
        else:
            return None

    def subprocess_info(self):
        if self._firmware_process and\
          self.step == self.steps.firmware_burning:
            return self._firmware_process.get_info_dict()
        else:
            return None

    def subprocess_process(self):
        return self._firmware_process

class TestPrintMetaprocess(SetupMetaProcess):
    """ A metaprocess for doing whatever type of calibration the machine
    requires.
    """
    def __init__(self, machine_manager, pymach, config, parser=None, filepath=None):
        _make_process_method_during(SetupMetaProcess.continue_process,
                                    ["test_print_intro",
                                     "test_print_complete",
                                     "test_print_error"])
        steps = ["test_print_intro",
                 "test_print",
                 "test_print_complete",
                 "test_print_error"]
        super().__init__(machine_manager, pymach, config, steps=steps)
        if parser is None:
            self._parser = machine_manager._libparser
        else:
            self._parser = parser
        if filepath is None:
            self._filepath = '/var/home/things/Examples/Chain Links.makerbot'
        else:
            self._filepath = filepath
        self._init_process()
        self.steps.extend(*[s for s in self._test_print_process._print_steps])

    def handle_error(self, error_dict):
        """ A handle_error for printprocess that overrides the default when
        printprocess is anything other than initializing
        """
        if not self.subprocess_process() or\
           self.subprocess_step() not in self.subprocess_process()._handled_steps:
            return super().handle_error(error_dict)
        else:
            return self.subprocess_process().handle_error(error_dict)

    def _init_process(self):
        self._client = self._machine_manager.process_method_client()
        if self._client is None:
            self._client = kaiten.client.Client(
                'printerpanel', 'printerpanel', 'pipe')
        self._test_print_process\
            = kaiten.processes.PrintProcess(self._machine_manager, self._pymach,
            self._parser, self._filepath, self._config, self._client,
            ensure_build_plate_clear=False)
        self._test_print_process._cancel_sound = False
        self._subprocess_methods = self._test_print_process._process_methods
        self.update_process_methods(self._subprocess_methods)
        self._machine_manager.clear_toolhead_error_memory()

    @staticmethod
    def settings_key():
        return "test_print"

    def intro_step(self):
        return self.steps.test_print_intro

    def error_step(self):
        return self.steps.test_print_error

    def complete_step(self):
        return self.steps.test_print_complete

    def process_step(self):
        return self.steps.test_print

    def subprocess_step(self):
        if self.step == self.steps.test_print:
            return self._test_print_process.step
        else:
            return None

    def subprocess_info(self):
        if self.step == self.steps.test_print:
            return self._test_print_process.get_info_dict()
        else:
            return None

    def subprocess_process(self):
        return self._test_print_process

    def contract_duration(self):
        """
        Override Implementation
        """
        if self.step == self.steps.test_print:
            return self._test_print_process.contract_duration()
        else:
            return datetime.timedelta(0, 0, 0, 5)

class SetupProcess(Process):
    """
    Generic process for printer first run experience

    @param machine_manager: The machine_manager object.  This process calls
        notify on that object to notify conneted clients of events.
    @param pymach: The pymachine object
    """
    def __init__(self, machine_manager, pymach, config,
                 jump_to_wifi_setup=False):
        self._config = config
        self._machine_manager = machine_manager
        self._pymach = pymach
        # An ordered tuple of metaprocesses to run
        available_metaprocesses = (WelcomeScreenMetaprocess,
                                   WifiSetupMetaprocess,
                                   LoadPrintToolMetaprocess,
                                   AssistedLevelingMetaprocess,
                                   LoadFilamentMetaprocess,
                                   ZCalibrationMetaprocess,
                                   TestPrintMetaprocess,
                                   EndMetaprocess,
                                   FirmwareBurningMetaprocess)

        mp_map = dict([(c.settings_key(), c) for c in available_metaprocesses])

        self._metaprocess_classes = [mp_map[c]
                                     for c
                                     in self._config['kaiten']['fre_steps']]
        self._current_metaprocess = 0
        self._metaprocesses = [obj(self._machine_manager,
                                   self._pymach,
                                   self._config)
                               for obj in self._metaprocess_classes]
        self._noback_steps = ['welcome_panel_knob',
                              'connecting']

        # These are dicts indexed by metaprocess class and then step. Like the
        # process method dict (which is generally ignored by this class because
        # process methods are passed through to metaprocesses) it is indexed by
        # metaprocess because metaprocesses may have duplicate steps that must
        # be handled differently - for instance, we can't say that skip() is
        # available on _every_ metaprocess's _running_ step because then you can
        # skip the final metaprocess.
        self.retry_process_methods = {}
        self.skip_process_methods = {}
        self.back_process_methods = {}
        for mp in self._metaprocesses:
            self.retry_process_methods[type(mp)] = {}
            self.skip_process_methods[type(mp)] = {}
            self.back_process_methods[type(mp)] = {}
            mp_steps = [s for s in mp.all_steps() if s not in
                        ['initializing', 'cleaning_up', 'cancelling', 'running', 'done']]
            for s in mp.retry_steps():
                self.retry_process_methods[type(mp)][s] = {'retry': self.retry}
            for s in mp_steps:
                if s not in self._noback_steps:
                    self.back_process_methods[type(mp)][s] = {'back': self.back}
            if mp is not self._metaprocesses[-1]:
                # don't let us skip the last metaprocess
                for s in mp_steps:
                    self.skip_process_methods[type(mp)][s] = {'skip': self.skip}
        self._set_contract_duration(5)
        self._must_reload = False
        super(SetupProcess, self).__init__(machine_manager, pymach, config)
        self.step = 'initializing'
        self.cancellable_toolhead_errors = set()
        self.ignorable_toolhead_errors = set()
        self.going_back = False
        self._stored_tasklets = None
        self._skip_metaprocess = None
        #make all pymach errors warnings rather than critical during setup process
        self.ignore_criticals = True

        if jump_to_wifi_setup:
            self._machine_manager.push_light_state('priority_busy')
            self._jump_to_wifi_setup()

    def _reload_metaprocesses(self):
        #preserve next_steps of current process on reload
        next_step = self._metaprocesses[self._current_metaprocess].next_step()
        self._metaprocesses = [obj(self._machine_manager,
                                   self._pymach,
                                   self._config) for obj in
                               self._metaprocess_classes]
        self._process_methods = self._get_process_methods()
        if self.going_back:
            self._metaprocesses[self._current_metaprocess].back_init()
            self.going_back = False
        self._metaprocesses[self._current_metaprocess]._next_step = next_step

    def _get_process_methods(self):
        """
        This overrides Process's implementation so it can add process methods
        from metaprocesses.
        """
        process_methods = {}
        for mp in self._metaprocesses:
            mp_methods = mp._process_methods
            mp_steps = mp.all_steps()
            # Attributes are stored along with a function (or bound method)'s
            # static information, not within a given instance of a bound method.
            # That means that when we tell SetupMetaProcess.continue_process
            # that it is a process method of half the metaprocess steps, it
            # carries that information around with every instantiation - so each
            # metaprocess will have a process_methods dict containing methods
            # for everything. This doesn't cause harm because those extra steps
            # will never get indexed, but still: gross. Trim them here.
            for step in list(mp_methods.keys()):
                if step not in mp_steps:
                    mp_methods.pop(step)
            for group in (self.retry_process_methods[type(mp)],
                          self.skip_process_methods[type(mp)],
                          self.back_process_methods[type(mp)]):
                for step in group.keys():
                    if step not in mp_methods:
                        mp_methods[step] = {}
                    for method_name in group[step].keys():
                        mp_methods[step][method_name] = group[step][method_name]
            process_methods[mp] = mp_methods
        return process_methods

    def _callable_methods(self):
        """
        This overrides Process's implementation so it can check the metaprocess
        step.
        """
        # if we're not running, nothing is going on
        if self.step != 'running':
            return {}
        callable_methods = {}
        if self.is_cancellable():
            # This should be callable from any step of any process
            # as long as the current process is cancellable
            callable_methods["jump_to_wifi_setup"] = self.jump_to_wifi_setup
        mp = self._metaprocesses[self._current_metaprocess]
        mp_methods = self._process_methods[mp]
        mp_step = mp.get_info_dict()['step']
        callable_methods.update(mp_methods.get(mp_step, {}))
        return callable_methods

    def _set_progress(self):
        """
        Unlike printing, we can just get the machine's percent, since we're
        only going to have one setpoint
        """
        self._progress = self._pymach.get_heater_progress_percent()

    def _do_run(self):
        # This slightly screwed up structure is required for atomicity. We have
        # to increment the metaprocess and swap out the metaprocess object at
        # the same time relative to yielding otherwise they may not be congruent
        self.step = self.steps.running
        finished = True
        self._current_metaprocess = -1
        while True:
            if finished:
                self._advance_metaprocess()
                finished = False
            if self._current_metaprocess >= len(self._metaprocesses):
                self.step = 'cleaning_up'
                self._current_metaprocess -= 1
                break
            processDone = False
            while not processDone:
                try:
                    finished = True
                    self.overrides_heater_watchdog = self._metaprocesses[self._current_metaprocess].override_watchdog_status()
                    if self._must_reload:
                        self._must_reload = False
                        self._reload_metaprocesses()
                        finished = False
                        processDone = True
                    yield next(self._metaprocesses[self._current_metaprocess].tasklets)
                except StopIteration:
                    processDone = True

    def cancel(self, error_dict=None):
        """
        Override required here because we must cancel our metaprocess before the setupprocess
        """
        self.tasklets.close()
        self.tasklets = self._cancel(error_dict)

    def _cancel_current_metaprocess(self):
        """ Just cancel the current metaprocess """
        try:
            mp = self._metaprocesses[self._current_metaprocess]
        except IndexError:
            pass
        else:
            mp.cancel()
            yield from mp.tasklets

    def _cancel(self, error_dict=None):
        """
        SetupProcess implementation

        Cancels the current metaprocess, then do all of the deferred
        assignments from cancel(), then run the superclass implementation
        of _cancel().
        """
        yield from self._cancel_current_metaprocess()
        self.cancelled = True
        if error_dict:
            self.failed = True
        self._cancellable = False
        self._step_change(self.steps.cancelling, error_dict)
        yield from super()._cancel(error_dict)

    def is_cancellable(self):
        try:
            mp = self._metaprocesses[self._current_metaprocess]
        except IndexError:
            return self._cancellable
        else:
            return self._cancellable and mp.is_cancellable()

    def _advance_metaprocess(self):
        """ Utility method to advance the metaprocess until one which should
        run is reached.
        """
        next_step = self._metaprocesses[self._current_metaprocess].next_step()
        next_metaprocess_index = None
        #grabbing the index of next_step if it is set
        if next_step is not None:
            for c in self._metaprocesses:
                if c.settings_key() == next_step:
                    next_metaprocess_index = self._metaprocesses.index(c)
                    break;
        if next_step is not None and next_metaprocess_index is None:
            self._log.warning("could not find index of next_step {0}"\
                              .format(next_process))
        if next_metaprocess_index is None:
            self._log.info("normal metaprocess advance")
            self._current_metaprocess += 1
            while self._current_metaprocess < len(self._metaprocesses)\
                  and not self._metaprocesses[self._current_metaprocess].should_run():
                self._log.info("mp {} should not run".format(self._current_metaprocess))
                self._current_metaprocess += 1
        else:
            idx = next_metaprocess_index
            self._metaprocesses[idx] =\
                                       self._metaprocess_classes[idx](self._machine_manager,
                                                                      self._pymach,
                                                                      self._config)
            #clear the next step so we don't try to loop forever
            self._metaprocesses[self._current_metaprocess]._next_step = None
            self._current_metaprocess = idx
            self._process_methods = self._get_process_methods()

    def _handle_skip(self):
        self._machine_manager._server.mixpanel_event("fre",
            self._machine_manager.process_method_client(), step=\
            self._metaprocesses[self._current_metaprocess].step, action="skipped")
        yield from self._metaprocesses[self._current_metaprocess]\
                       .handle_skip()
        self._advance_metaprocess()
        self._must_reload = True

    def skip(self):
        """
        Skip the current metaprocess and immediately begin the next.
        """
        self._insert_tasklets(self._handle_skip())

    def retry(self):
        """
        Retry the current metaprocess. Only available when metaprocesses say so.
        Take that, static analysis!
        """
        self._insert_tasklets(self._handle_back(True))

    def _handle_back(self, ignore_should_run):
        """
        Handle moving back to previous metaprocesses
        destination metaproc depends on return value of current_metaprocess handle_back()
        True: Current metaprocess remains current
        False: Previous metaprocess with should_run() == True becomes current
        """
        self._machine_manager._server.mixpanel_event("fre", 
            self._machine_manager.process_method_client(), step=\
            self._metaprocesses[self._current_metaprocess].step, action="back")
        result = yield from self._metaprocesses[self._current_metaprocess].handle_back()
        if result == False:
            self.going_back = True
            self._current_metaprocess -= 1
            # If this came from a retry we shouldn't listen to metaprocesses
            # saying they shouldn't run
            if not ignore_should_run:
                while not self._metaprocesses[self._current_metaprocess]\
                              .should_run():
                    #go back to the first metaprocess that should run
                    self._current_metaprocess -= 1
            self._must_reload = True

    def back(self):
        """
        Go back to the previous metaprocess, if possible.
        """
        self._insert_tasklets(self._handle_back(False))

    def _jump_to_wifi_setup(self, reload=False):
        """
        Ignore the current process and jump to wifi setup
        """
        mp_idx = self._metaprocess_classes.index(WifiSetupMetaprocess)
        self._current_metaprocess = mp_idx
        mp = self._metaprocesses[mp_idx]
        mp._next_step = None
        if reload:
            # Instead of deferring the reload until we get back to _do_run,
            # just do it here so we can skip to the step we want
            self._reload_metaprocesses()
            mp = self._metaprocesses[mp_idx]
        mp.jump_to_wifi_setup()

    def _cancel_and_jump_to_wifi_setup(self):
        """
        Cancel the current process and then jump
        """
        yield from self._cancel_current_metaprocess()

        self._jump_to_wifi_setup(reload=True)

    def jump_to_wifi_setup(self):
        """
        Jump to the wifi setup step of wifi setup
        """
        self._machine_manager.push_light_state('priority_busy')
        self._insert_tasklets(self._cancel_and_jump_to_wifi_setup())

    def get_info_dict(self):
        if self.step == 'running':
            to_return \
                = self._metaprocesses[self._current_metaprocess].get_info_dict()
            to_return['methods'] = self.callable_method_names()
            return to_return
        else:
            sid = super().get_info_dict()
            sid['setup_step'] = 'initializing'
            return sid

    def contract_duration(self):
        """
        Superclass Implementation
        """
        return self._metaprocesses[self._current_metaprocess].contract_duration()

    def _set_contract_duration(self, time_ms):
        """
        PrintProcess Implementation
        """
        self._contract_duration = datetime.timedelta(0, 0, 0, time_ms)

    def contract_duration(self):
        """
        PrintProcess Implementation
        """
        return self._contract_duration

    def _get_ignorable_toolhead_errors(self):
        return self._metaprocesses[self._current_metaprocess]\
                   .ignorable_toolhead_errors

    def _get_cancellable_toolhead_errors(self):
        # We shouldn't let toolhead errors cancel us, basically
        return set()

    def handle_error(self, error_dict):
        """
        PrintProcess Implementation
        """
        current_metaprocess = self._metaprocesses[self._current_metaprocess]
        return current_metaprocess.handle_error(error_dict)

    def _insert_tasklets(self, generator):
        """
        Insert the generator to be run before continuing tasklets

        This replaces tasklets with a wrapper that will run the given
        generator and then restore tasklets to its original value.
        """
        stored_tasklets = self.tasklets
        def wrapper():
            try:
                yield from generator
            except (Exception, GeneratorExit):
                stored_tasklets.close()
                raise
            else:
                self.tasklets = stored_tasklets
                # Since we are being iterated as self.tasklets, and we just
                # overwrote that, we need to yield one more time in order to
                # avoid raising StopIteration (which would halt iteration of
                # the original tasklets object).  We will not return from
                # this yield.
                yield
        self.tasklets = wrapper()

    def _do_cleanup(self):
        # Do not automatically run the setup process once it
        # has been completed or skipped
        if os.path.isfile(kaiten.constants.do_fre):
            os.remove(kaiten.constants.do_fre)

        self._log.info("Setupprocess ensuring tether is disabled")
        yield from self._machine_manager._server.dbus_manager.ensure_tether(False)
