import contextlib
import copy
import ctypes
import errno
import json
import os
import pickle
import sys
import time
import datetime
import shutil
import traceback

import mbcoreutils.common_settings
import mbcoreutils.machine_definitions
import mbcoreutils.tool_mappings
import mbcoreutils.toolhead_errors

import kaiten.constants
import kaiten.decorator
import kaiten.enum
import kaiten.error
import kaiten.light_manager
import kaiten.log
import kaiten.processes
import kaiten.util
if kaiten.constants.mock:
    import kaiten.mock
    import libmachine.pymachine_virtual as pymachine
else:
    import libmachine.pymachine as pymachine

from kaiten.jsonrpc import JsonRpcException

class ProcessGenerator(object):
    def __init__(self, machine_manager, process):
        self._machine_manager = machine_manager
        self._log = kaiten.log.getlogger(self)
        self._process = process

    def __next__(self):
        # IsInitialized is safe to call even when libmachine is disbaled
        if not self._machine_manager._pymach or\
           self._machine_manager._pymach.is_initialized():
            self._machine_manager._iterate()
            self._machine_manager._iterate_process()
        else:
            self._log.debug("Machine not initialized yet...")

    def contract_duration(self):
        return self._process.contract_duration()

    def expected_run_time(self):
        return datetime.timedelta(seconds=kaiten.constants.normal_generator_time)

class LightContextManager():
    def __init__(self, machine_manager, state, condition=True):
        self._machine_manager = machine_manager
        self._state = state
        self._condition = condition

    def __enter__(self):
        if self._condition:
            self._machine_manager.push_light_state(self._state)

    def __exit__(self, *exc):
        if self._condition:
            self._machine_manager.pop_light_state(self._state)

class MachineManager(object):
    """
    The machine manager.  Handles iterating the machine and the current process.
    The machine is a pointer to a C object, and the process is a python generator.
    We use a system of error codes to report back errors.  Both the process and
    the machine object return error codes defined in machine_definitions.py.  We
    interpret that error code and determine if we should continue, terminate the
    process, or terminate the machine.  Regardless, we always inform all of our
    connected clients that an error has been encountered.
    """
    def __init__(self, server, config, register_callback=None,
                 libmachinefunc=None, libparserfunc=None):
        self._log = kaiten.log.getlogger(self)
        self._server = server
        self._config = config
        self._current_process = None
        self._iteration = 0
        self._register_callback = register_callback
        self._last_watchdog_reset = datetime.datetime.utcnow()
        self._extruders_changed_during_process = set()
        # error counter for unique ids
        self._error_id_counter = 0
        self._force_extruder_cache = False
        # Massage settings that used to be called something else
        if 'configured_tool' in config['kaiten']:
            self._log.info("Updating configured tool")
            config['kaiten']['configured_tools']\
                = [config['kaiten']['configured_tool']]
            del config['kaiten']['configured_tool']
        self._log.info("count: {}".format(self.count_extruders()))
        self.initialize_configured_tools()
        self._log.info("Initialized configured tools to {}".format(self.configured_tools))

        self._set_toolhead_mappings()

        self._process_method_client = None
        if not libparserfunc:
            libparserfunc = self._get_libparser
        self._libparser = libparserfunc()
        self._libmachine_enabled = True
        # BAD BADB ADB ADB AD BAD

        self._queue_open = False
        self._queue = []
        self._last_running_process = None

        # The config is not suitable to be passed to libmachine until we
        # load tool specific configs.  So we load settings for the last
        # configured tool, if it exists.
        self._set_extruder_config(self.configured_tools)

        # These errors should still send a warning even if bot is idle.
        self._idle_warning_errors = {
            kaiten.error.heater_rise_watchdog_triggered,
            kaiten.error.watchdog_triggered,
            kaiten.error.heater_temperature_sag_triggered,
            kaiten.error.heater_temperature_overrun_triggered,
            kaiten.error.carriage_not_connected,
            kaiten.error.chamber_not_connected
        }
        # These errors are ALWAYS ignored.
        # This list can be modified by clients via jsonrpc.
        self._disabled_toolhead_errors\
            = set([mbcoreutils.toolhead_errors.error.get(de)
                   for de in self._config["kaiten"]["disabled_errors"]
                   if de in mbcoreutils.toolhead_errors.error])

        # A queue for processes that need to get run when the machine becomes
        # idle again.
        import collections
        self._process_queue = collections.deque()
        # The last error code receieved from the machine
        self._last_error_code = None
        self._requested_ids = set()

        # This dict is organized by toolhead index, and maintains
        # all relevant state information related to toolheads.
        # Each toolhead has a dict with all of the keys from
        # the machine status packet, and:
        # last_error
        # type
        # tried_upload
        self.toolhead_status = self._init_toolhead_status()
        # If any toolhead is currently hot
        self._th_hot = False

        # This dict gets sent out in system/state notification
        self._system_info = {
            "toolheads" : {},
            "current_process" : None,
            "disabled_errors" : []
        }
        self.last_th_error_seen = datetime.datetime.utcnow()
        # toolhead and machine errors get mapped to a error severity
        # based on error code and the context of the machine
        # ignorable - no action is taken
        # warning - process can handle by taking action (i.e. suspending)
        #           or a notification is sent out
        # process_critical - error causes active process to cancel
        self._error_severity = kaiten.enum.enum("error_severity",
            "ignorable",
            "warning",
            "process_critical"
            )
        self._process_id = 0
        pymachine_result = self.create_pymachine()
        if pymachine_result != kaiten.error.ok:
            self._error_repeat_counter = 2
            def bad_iterate():
                error_dict = {
                    "code": pymachine_result,
                    "source": '',
                    "error_id": 200
                }
                if self._error_repeat_counter == 0:
                    self._error_notification(error_dict)
                    self._error_repeat_counter = 100
                self._error_repeat_counter -= 1

            self._light_manager = kaiten.light_manager.LightManager(None, self._config)
            self._normal_iterate = self._iterate
            self._iterate = bad_iterate
            return

        os.makedirs(kaiten.constants.current_print_dir, exist_ok=True)
        self._light_manager = kaiten.light_manager.LightManager(self._pymach, self._config)

    def _set_toolhead_mappings(self):
        """
        Update a bunch of internal fields based on the toolheads config

        The toolheads config as it comes in not well structured for a lot of
        the things that we want to do with it.  So we create some mappings
        here for dealing with that.
        """
        self._toolheads_by_index = {}
        for name, th in self._config['toolheads'].items():
            from itertools import zip_longest as ziplong
            try:
                assist_axes = th['assist']
            except KeyError:
                assist_axes = []
            for location, axis_name, assist in ziplong(
                    th['locations'], th['axes'], assist_axes):
                toolhead = th.copy()
                del toolhead['locations']
                del toolhead['axes']
                try:
                    del toolhead['assist']
                except KeyError:
                    pass
                toolhead.update({
                    'name': name,
                    'location': location,
                    'assist': assist
                })
                if axis_name is not None:
                    toolhead['axis_name'] = axis_name
                self._toolheads_by_index[location] = toolhead

        self._toolheads_by_axis = {
            th['axis_name']:th for th in self._toolheads_by_index.values()
            if 'axis_name' in th
        }

    def assist_from_index(self, index):
        """ Toolhead index -> assist axis for toolhead"""
        return self._toolheads_by_index[index]['assist']

    def axis_from_index(self, index):
        """ Toolhead index -> axis name"""
        return self._toolheads_by_index[index]['axis_name']

    def index_from_axis(self, axis):
        """ Axis number/name -> th index"""
        if isinstance(axis, int):
            axis = mbcoreutils.machine_definitions.axis_names[axis]
        return self._toolheads_by_axis[axis]['location']

    def count_extruders(self):
        extruders=0
        for th in self._config['toolheads'].values():
            if 'extruder' in th['type']:
                extruders += len(th['locations'])
        return extruders

    def initialize_configured_tools(self):
        inval_id = mbcoreutils.tool_mappings.invalid_tool.id
        def_ids = [inval_id] * self.count_extruders()
        tools = [mbcoreutils.tool_mappings.Tool.from_id(t)
                 for t in self._config['kaiten'].get('configured_tools', def_ids)]
        self.configured_tools = tools

    def create_pymachine(self):
        try:
            self._pymach = pymachine.Machine(self._config, kaiten.constants.machine_path)
        except Exception:
            self._log.error("Failed to create pymachine", exc_info=True)
            self._pymach = None
            return kaiten.error.machine_driver_failure
        # Load the printer settings from kaiten's dict
        settings_str = bytes(json.dumps(self._config), 'UTF-8')
        for result in self._pymach.initialize_from_settings(settings_str):
            pass
        if result != kaiten.error.ok:
            self._log.error("libmachine config parse failure: %s",
                            kaiten.error.error_to_string[result])
            # A bunch of things are now completely broken and it's not safe
            # to do much of anything!
            self._pymach.close_machine_driver()
            self._pymach = None
        else:
            self._log.info("libmachine initialized from config")
        return result

    def get_current_process(self):
        return self._current_process

    def _get_process_id(self):
        """
        Generates a unique process id
        """
        self._process_id += 1
        return self._process_id

    def _count_toolheads(self):
        th_config = self._config['toolheads']
        toolheads = 0
        for toolhead_type in th_config:
            toolheads += len(th_config[toolhead_type]['locations'])
        return toolheads

    def _init_toolhead_status(self):
        th_config = self._config["toolheads"]
        toolheads = {}
        for toolhead_type in th_config:
            for loc in th_config[toolhead_type]["locations"]:
                toolheads[loc] = {
                    "type": self._get_toolhead_type(toolhead_type),
                    "last_error": None,
                    "tried_upload": False,
                    "error": kaiten.error.none
                }
        self._config['toolhead_count'] = len(toolheads.keys())
        return toolheads

    def _get_toolhead_type(self, printer_settings_type):
        """
        This map can hopefully go away when we revise toolhead code generattion
        and the machine/kaiten toolhead struct
        """
        toolhead_category_map = {
            "bronx" : "extruder",
            "foley": "extruder",
            "chamber" : "chamber",
        }
        return toolhead_category_map.get(printer_settings_type, "unknown")

    def extruder_count(self):
        toolheads = self.toolhead_status.values()
        return sum(1 for t in toolheads if t['type'] == "extruder")

    def clear_toolhead_error_memory(self):
        for toolhead in self.toolhead_status.values():
            toolhead["last_error"] = None

    def stop(self):
        if self._current_process is not None:
            self._current_process.stop()

    def light_context(self, state):
        return LightContextManager(self, state, True)

    def conditional_light_context(self, state, condition):
        return LightContextManager(self, state, condition)

    def push_light_state(self, new_light_state):
        self._light_manager.push_state_to_stack(new_light_state)

    def pop_light_state(self, state):
        self._light_manager.pop_state_from_stack(state)

    def push_error_light_state(self):
        self._light_manager.push_state_to_stack("error")

    def clear_error_light_states(self):
        self._light_manager.clear_state_from_stack("error")

    def pop_error_light_state(self):
        self._light_manager.pop_state_from_stack("error")

    def push_light_hold_state(self, priority):
        self._light_manager.push_hold_state_to_stack(priority)

    def cleanup_machine(self):
        if self._pymach:
            self._pymach.close_machine_driver()

    @contextlib.contextmanager
    def disable_toolhead_spi(self):
        self._log.info("Disabling machine driver")
        self._pymach.disable_spi()
        self._libmachine_enabled = False
        try:
            yield
        finally:
            self._libmachine_enabled = True
            self._pymach.enable_spi()
            self._log.info("Reenabled machine driver")

    def reload_config(self, config):
        """
        Reloads this config as the global config, but doesn't pass the
        settings to the machine driver since this can be run during a
        print.  Currently nothing that invokes this through the server
        modifies any values that libmachine cares about, but we should
        probably handle this better somehow.
        """
        self._config = config
        if not self._pymach:
            # We get to try again to make our pymachine
            if self.create_pymachine() == kaiten.error.ok:
                self._iterate = self._normal_iterate
            else:
                return

        self._set_toolhead_mappings()

        self._extruder_localize()
        attached_tool = self._pymach.get_tool_id(0)
        if 'configured_tools' not in config['kaiten'].keys():

            # We probably just reset to factory. We should make sure
            # to update the cached extruder from libmachine next time
            # we iterate (we can't do it here, because that implies
            # changing the home config and therefore recursing forever)
            self._force_extruder_cache = True
        self.initialize_configured_tools()
        self._set_extruder_config(self.configured_tools)
        self._disabled_toolhead_errors\
            = set([mbcoreutils.toolhead_errors.error.get(de)
                   for de in self._config["kaiten"]["disabled_errors"]
                   if de in mbcoreutils.toolhead_errors.error])

    def _extruder_localize(self, tool_uid=None):
        """
        Update all configurations with values calibrated for the specific
        extruder currently attached.  Anything that depends only on the
        type of extruder should go in _set_extruder_config instead.
        In addition to when we detect a new extruder, this should be
        invoked when we reload config.
        """
        if not tool_uid:
            tool_uid = self._pymach.get_tool_uid(0)
        if not tool_uid:
            return
        tool_uid = str(tool_uid)
        for key in ("home",):
            update = self._config[key]['per_extruder'].get(tool_uid, {})
            kaiten.util.recursive_update(self._config[key], update)

    def _set_extruder_config(self, tools, materials=None):
        """
        Update our configuration based on the extruder specified by tool,
        which should be an instance of tool_mappings.Tool.  This must be
        invoked on initialization, when we switch extruder types, and
        when we reload config.
        """
        self._log.info("Updating settings for {}".format(repr(tools)))
        if None is materials:
            materials = [None]*len(tools)
        for tool, material, idx\
            in zip(tools, materials, list(range(len(tools)))):
            if not tool or not tool.valid():
                self._log.info("Choosing arbitrary tool until we get a real tool")
                # Choose a tool that we have a profile for
                supported_types = set(self._config['extruder_profiles'])
                valid_tools = mbcoreutils.tool_mappings.valid_tools
                tool = [t for t in valid_tools if t.type in supported_types][0]
            self._log.info("Generating settings for tool %s", tool.type)
            if tool.type not in self._config['extruder_profiles']:
                raise kaiten.error.UnrecognizedToolError(tool.type)
            def set_axis(axis_name, d):
                ret = {}
                for k, v in d.items():
                    key = k
                    if key == '-':
                        key = axis_name
                    if isinstance(v, dict):
                        ret[key] = set_axis(axis_name, v)
                    else:
                        ret[key] = v
                return ret

            axis = self.axis_from_index(idx)
            tool_config = set_axis(axis,
                                   self._config['extruder_profiles'][tool.type])
            self._log.info("Generated config {}".format(tool_config))
            kaiten.util.recursive_update(self._config, tool_config)
            available_materials = tool_config['materials']
            if material not in available_materials:
                material = tool_config['material_default']
            material_config = available_materials[material]
            self._log.info("Updating settings for material %s", material)
            kaiten.util.recursive_update(self._config, material_config)

    def get_type(self):
        return "machine_manager"

    def get_info_dict(self):
        return self._system_info

    def process_method_client(self):
        return self._process_method_client

    def __next__(self):
        self._iterate()

    @staticmethod
    def _get_libparser():
        if kaiten.constants.mock:
            return kaiten.mock.libparser
        return ctypes.CDLL(kaiten.constants.parser_path)

    def _update_toolhead_info(self):
        """
        Updates the system_info dict with a specific
        subset of the current toolhead status.
        """
        toolheads = {}
        for index, status in self.toolhead_status.items():
            toolhead_type = status["type"]
            if toolhead_type not in toolheads:
                toolheads[toolhead_type] = []
            # we only want a subset of toolhead keys
            th_dict = {
                "index": index,
                "preheating": bool(status.get("preheating", False)),
                "current_temperature": status.get("current_temperature", 0),
                "target_temperature": status.get("target_temperature", 0),
                "tool_present": bool(status.get("tool_id", 0) > 0),
                "tool_id": status.get("tool_id", 0),
                "filament_presence": bool(status.get("filament_presence")),
                "error": status.get("error", 0),
            }
            if "door_open" in status:
                th_dict["door_open"] = bool(status["door_open"])
            toolheads[toolhead_type].append(th_dict)
        self._system_info["toolheads"] = toolheads

    def _update_toolhead_status(self, index, status):
        """
        Update the full toolhead_status, and return values indicating whether
        callbacks are required. Because some of those callbacks require data
        not set here, we don’t actually do them now.

        Returns a 3-tuple (reload_machine_config, tool_changed, tool).
        reload_machine_config will be true if we should reload the machine
        config. This is either because the tool _type_ has changed, or because
        some other random part of Kaiten has requested we flush the extruder
        configuration by setting self._force_extruder cache.
        tool_changed will be true if the tool changed at all, even if the type
        didn’t.
        tool is the tool object.
        """
        # Note that toolhead_status is a reference to the object in
        # self.toolhead_status[index], so mutating it will mutate
        # the object there
        toolhead_status = self.toolhead_status[index]
        # Everything other than updating the toolhead_status in here is
        # extruder specific, chambers need not enter
        if toolhead_status['type'] == 'extruder':
            extruder_changed = toolhead_status.get('tool_id') != status['tool_id']
            toolhead_status.update(status)
        else:
            if toolhead_status['type'] != 'chamber':
                # Let’s dump a warning if this isn’t a chamber type, it will be
                # spammy if we don’t remove it but that’s literally why it’s
                # there since we’re just doing a chained if/else comparing
                # strings
                self.log.warning("TH status idx {} has type {}, full dump {}"\
                                 .format(index, toolhead_status['type'], status))
            # We should make sure to update our status even if this is a chamber
            toolhead_status.update(status)
            # The second value in our return tuple is added to a list
            # of tools to be updated, since our chamber does not have a tool
            # we want to make sure that it doesn't get added to that list
            return False, False, None

        tool = mbcoreutils.tool_mappings.Tool.from_id(status['tool_id'])
        if extruder_changed or self._force_extruder_cache:
            # Per specific extruder settings always get updated,
            # but don't need to be passed to libmachine
            self._extruder_localize()

            # The rest of the settings do need to be passed to machine, but
            # we currently only update them if the tool type changes.  So this
            # only gets invoked at boot when we first detect an attached
            # extruder, or when we actually switch extruder types.

            reload_machine_config = (tool.valid() and
                                     tool.type != self.configured_tools[index].type)
            if self._force_extruder_cache:
                reload_machine_config = True
                self._force_extruder_cache = False

            return reload_machine_config, extruder_changed, tool
        return False, False, tool

    def _update_current_tools(self, tools):
        """
        Take a list of tools that have changed type and require new configs,
        configure the new settings, and update the system.

        @param tools List of either mbcoreutils.Tool objects or Nones. Should
                     always have an entry for each tool in the system. A None
                     in place of a tool indicates that tool has not changed,
                     and should not be updated.
        """
        # Generate a new list of tools that replaces any Nones with entries
        # from configured_tools, and cache if we actually have anything new
        updated_tools = []
        saw_change = False
        for idx, t in enumerate(tools):
            if None is not t:
                self.configured_tools[idx] = t
                updated_tools.append(t)
                saw_change = True
            else:
                updated_tools.append(self.configured_tools[idx])
        # If there’s nothing new, we really don’t want to be changing our
        # configs
        if not saw_change: return
        self._set_extruder_config(updated_tools)
        new_dict = {'configured_tools': [t.id for t in updated_tools]}
        self._server.update_home_config(new_dict)
        settings_bytes = bytes(json.dumps(self._config),
                               'UTF-8')
        for task in self._pymach.initialize_from_settings(settings_bytes):
            pass
        if task != kaiten.error.ok:
            self._log.error("pymachine initialization failed: %s",
                            kaiten.error.error_to_string[task])
        for x in self._pymach.load_filament_jam_settings(0,
                                                         self._config["steps_per_mm"]["a"]):
            if (x == kaiten.error.not_ready):
                self._log.info("Machine not ready, iterating machine")
                self._pymach.iterate()
            pass


    def _notify_extruder_change(self, index, only_uncalibrated=False):
        """
        Send an extruder change notification

        If only_uncalibrated is set to True we will only send this notification
        when we have an extruder attached that needs to be calibrated.
        """
        new_config = self.get_extruder_config(index)
        params = {
            'index': index,
            'config': new_config,
        }

        # get_extruder_config is already checking if no tool is attached or
        # if we don't actually need to calibrate new extruders.
        if not only_uncalibrated or not new_config['calibrated']:
            self._server.notify_clients('extruder_change', params)

    def _set_status_struct(self, machine_dict):
        """
        Parses the system notification returned from the machine object and
        updates self._system_info

        NB: the notification is a struct that is defined by various files in the
        meta directory of Birdwing-Software.  A struct is machine generated, with
        identical definitions being created for both the machine and kaiten.
        """
        toolhead_dict = {}
        tools_whose_type_changed = []
        tools_who_changed_at_all = []
        connected_tools = []
        for idx in range(len(machine_dict['toolhead_status'])):
            if idx not in self.toolhead_status:
                self._log.error("Unexpected toolhead index!")
                break
            type_changed, tool_changed, tool\
                = self._update_toolhead_status(idx,
                                               machine_dict['toolhead_status'][idx])
            # tool will be None if toolhead is a chamber
            if tool:
                # Keep a list of tools that have changed for later notifications.
                # If the type changed, we always send a notification. If not, we
                # only send a notification if the new tool isn’t calibrated.
                # We make sure these two lists are disjoint.
                if type_changed:
                    tools_whose_type_changed.append((idx, tool))
                    # Only update tools whose type has changed
                    connected_tools.append(tool)
                else:
                    # Put a placeholder in - update_current_tools expects this
                    connected_tools.append(None)
                    if tool_changed:
                        tools_who_changed_at_all.append((idx, tool))
        self._update_current_tools(connected_tools)
        if tools_whose_type_changed or tools_who_changed_at_all:
            # This method must be called before calling notify_extruder_change
            # to actually get fresh data
            for (idx, t) in tools_whose_type_changed + tools_who_changed_at_all:
                self._server.mixpanel_event("extruder_change", to=t.name)
                if self._current_process != None:
                    self._extruders_changed_during_process.add(idx)
            for (index, _) in tools_whose_type_changed:
                # always update
                self._notify_extruder_change(index, False)
            for (index, _) in tools_who_changed_at_all:
                # only update if not calibrated
                self._notify_extruder_change(index, True)
        if self._count_toolheads()\
           != len(machine_dict['toolhead_status']):
            # The length of the machine return will depend on the config, so
            # if we call init_toolhead_status again it'll be  up to date
            self._log.info("Resetting toolhead status")
            self.toolhead_status = self._init_toolhead_status()
        else:
            # If we're in here, sadly our nice toolhead_count entry has been
            # wiped out by reloading the config from dict so we should reset it
            self._config['toolhead_count'] = self._count_toolheads()
        self._update_toolhead_info()

    def state_notification(self):
        """
        Notifies connected clients of its state change.
        """
        self._update_process_info()
        self._server.state_notification()

    def _error_notification(self, error_dict):
        """
        Notifies connected clients of an error. A unique error_id is attached
        to the outgoing message.

        @param errno: The error number
        @param source: Toolhead originating this error
        """
        self._log.debug("Errorno: %i, Error id: %d",
            error_dict["code"], error_dict["error_id"])
        method = 'error_notification'
        self._server.notify_clients(method, error_dict)

    def _assess_machine_error_severity(self, error_code):
        # determine severity from error number
        constants = mbcoreutils.machine_definitions.constants
        if error_code < constants['warning_threshold']:
            return self._error_severity.ignorable
        elif error_code < constants['process_error_threshold']:
            return self._error_severity.warning
        else:
            return self._error_severity.process_critical

    def _handle_error(self, error_code, severity, error_source=None):
        if severity == self._error_severity.ignorable:
            return

        self._log.error("Handling error: {0}, severity: {1}".format(
            error_code, severity))

        send_notification = True
        error_dict = {
            "code": error_code,
            "source": error_source,
            "error_id": self._error_id_counter,
        }

        if severity == self._error_severity.process_critical:
            self._log.error("Critical error code %i", error_code)
            if self._current_process != None and self._current_process.is_cancellable():
                if not self._current_process.ignore_criticals:
                    self._cancel_process(error_dict)
                    send_notification = False
                else:
                    self._server.play_buzzer("error")
                    if self._current_process.handle_error(error_dict):
                        send_notification = False
            else:
                self._uncancellable_cleanup(error_code)
        else:
            self._server.play_buzzer("error")
            # give the process a chance to handle this error
            if self._current_process is not None:
                if self._current_process.handle_error(error_dict):
                    send_notification = False

        if send_notification:
            #Set the error light state if clients are notified of the error
            # EXCEPT (HORRIBLE HACK) if the error code is the heater hold notification
            # TODO: archtitectural distinctions between notifcations, warnings and errors
            self.push_error_light_state()
            self._error_notification(error_dict)
            # Processes should also handle their own analytics if they don't
            # want to send error notifications
            error_attributes = {
                "error_id": self._error_id_counter,
                "error_type": error_code
            }
            self._server.mixpanel_event("error", **error_attributes)

        self._error_id_counter += 1

    def _uncancellable_cleanup(self, error_code):
        """
        Cleanup for critical errors on uncancellable processes

        We always try to let processes handle their own errors when
        possible, but when thing go really wrong this is not always
        possible.  So there are a few generic cleanup steps that we
        want to run through when this happens.
        """
        if error_code == kaiten.error.operation_timed_out:
            # Currently all of our timeouts are triggered when the
            # toolhead stops responding as we expect.  Resetting its
            # power is generally enough to fix this.
            # TODO: Are there other cases when we want to do this?
            self._log.error("Toolhead unresponsive -- toggling power")
            self._pymach.toggle_toolhead_power(0, False)
            self._pymach.toggle_toolhead_power(0, True)
            # We never want to leave the motors enabled
            self._pymach.fast_abort()
        else:
            self._log.error("The critical error {} occurred but the process "
                            "wasn't cancellable".format(error_code))

    def _error_acknowledged(self, error_id):
        method = 'error_acknowledged'
        params = {
            'error_id' : error_id
        }
        self._server.notify_clients(method, params)

    def _is_toolhead_warning(self, error_code):
        """
        Toolhead error codes > toolhead_warning_threshold are
        generally only information for the machine, not errors
        that should cause actions visible to users.
        Chris Moore likes this function.
        """
        constants = mbcoreutils.machine_definitions.constants
        return error_code > constants["toolhead_warning_threshold"]

    def _eval_toolhead_error_code(self):
        """
        Evaluates a toolhead error codes in the status struct.  Toolhead errors
        are more persistant than machine errors, so we always keep track of the
        last error we received and only wait_for_acknowledge for new errors.
        """
        for toolhead in range(self._config['toolhead_count']):
            toolhead_status = self.toolhead_status[toolhead]
            error_code = toolhead_status["error"]
            # create source dict with toolhead index and type
            source = {
                "index": toolhead,
                "type": toolhead_status["type"]
            }

            # We always want to skip non errors, but we're adding a bit of logic
            # to catch certain errors that are in the bronx, like error 66.
            # These errors occur periodically if the error state persists - so,
            # you've got a bad connection, what you get is error 66 appearing
            # every couple seconds. So let's debounce this error handling
            # mechanic to a configurable level so we don't get a bunch of error
            # notifications if this happens.
            now = datetime.datetime.utcnow()
            if error_code == kaiten.error.none:
                if (now-self.last_th_error_seen).seconds\
                   >= self._config['kaiten']['toolhead_error_debounce_time']:
                    error_code = kaiten.error.none
                continue

            self.last_th_error_seen = now
            # This should only happen if the build is broken
            if error_code not in kaiten.error.toolhead_errors:
                self._log.info("UNDEFINED TOOLHEAD ERROR %d"% error_code)
                #but actually let's not crash
                error_code = kaiten.error.invalid_response

            # We also ignore warnings and disabled errors, and do not let them
            # "interrupt" other errors
            if self._is_toolhead_warning(error_code) or \
                error_code in self._disabled_toolhead_errors:
                continue

            # If there is no active process, machine manager handles
            # setting severity, otherwise use cancellable and ignorable
            # toolhead error dicts processes define
            if self._current_process is None or \
                 self._current_process.cancelled:
                # We do not have any active processes, so we ignore
                # almost all errors
                if error_code in self._idle_warning_errors:
                    severity = self._error_severity.warning
                else:
                    continue
            else:
                # Use the process' ignorable errors
                ignorables = set(self._current_process.ignorable_toolhead_errors)
                cancellables = set(self._current_process.cancellable_toolhead_errors)
                if error_code in ignorables:
                    continue
                elif error_code in cancellables:
                    severity = self._error_severity.process_critical
                else:
                    severity = self._error_severity.warning

            # When we get the same error repeatedly, we only handle it once
            if toolhead_status["last_error"] == error_code:
                continue
            toolhead_status["last_error"] = error_code
            self._log.info("Set last toolhead error to {}".format(toolhead_status['last_error']))

            # Check if we should try to schedule a bronx upload.
            if (error_code == kaiten.error.carriage_not_connected or
                error_code == kaiten.error.chamber_not_connected
                and self._config["kaiten"]["implicit_bronx_upload"]):
                cancel = self._implicit_bronx_upload(toolhead)
                if cancel:
                    # If we do schedule an upload, we need to cancel
                    # the current process.
                    severity = self._error_severity.process_critical

            self._handle_error(error_code, severity, source)

    def _implicit_bronx_upload(self, toolhead):
        """
        Kick off a bronx upload if we have not already failed an upload
        and do not already have an upload queued. Return whether or not
        we kicked off a process.
        """
        is_toolhead_lambda = lambda p: isinstance(p, kaiten.processes.BronxUploadProcess)
        queued_toolhead_process = any(map(is_toolhead_lambda, self._process_queue))
        running_toolhead_process = is_toolhead_lambda(self._current_process)
        if queued_toolhead_process or running_toolhead_process:
            self._log.info("Toolhead upload process already queued")
            return False
        elif self.toolhead_status[toolhead]["tried_upload"]:
            self._log.info("Toolhead still disconnected, but tried"
                           " too many times, giving up")
            return False
        else:
            self._log.info("Toolhead disconnect, queueing toolhead upload process")
            def get_fw_path(loc):
                for th in self._config["toolheads"].values():
                    if loc in th["locations"]:
                        return th["program"]
                raise RuntimeError("Got error for unknown toolhead")
            self._process_queue.append(self.get_bronx_upload_process(
                get_fw_path(toolhead), toolhead))
            self.toolhead_status[toolhead]["tried_upload"] = True
            return True

    def _eval_machine_error_code(self, error_code):

        if error_code is None:
            sev = self._error_severity.ignorable
        else:
            sev = self._assess_machine_error_severity(error_code)

        # check if error_code is the same
        if error_code == self._last_error_code:
            sev = self._error_severity.ignorable
        else:
            self._last_error_code = error_code
        self._handle_error(error_code, sev)

    def _handle_python_exception(self, exception):
        """
        Translates a python error into an error code.

        @param exception: Python exception to translate.
        """
        self._log.info("Critical process error 1500: Python exception. Terminating active process",
                       exc_info=True)
        # Create analytics event with python backtrace on error 1500
        analyticsbacktrace = traceback.format_exc()
        analyticsbacktrace = analyticsbacktrace.rstrip().split("\n")
        error_code = kaiten.error.critical_kaiten_error
        severity = self._error_severity.process_critical
        error_attributes = {
            "error_id": self._error_id_counter,
            "error_type": error_code,
        }
        i = 0
        j = len(analyticsbacktrace)
        for line in analyticsbacktrace:
            i+=1
            name = "stack_trace_"+str(j-i)
            error_attributes[name] = line

        if self.get_current_process() is not None:
            error_attributes.update({'process_id' : self.get_current_process().get_id()})
            error_attributes.update({'process_name' : self.get_current_process().get_name()})

        self._server.mixpanel_event("error", **error_attributes)
        self._handle_error(error_code, severity)

    def _iterate(self):
        """
        Iterate the machine driver.
        """
        # If the state is idle and we have a queued process, pop it off and
        # register it
        if self._current_process is None and len(self._process_queue) > 0:
            process = self._process_queue.popleft()
            self.register_process(process) # Should set state to running
        if not self._libmachine_enabled:
            self._update_process_info()
            return
        if (self._current_process is not None) and self._current_process.overrides_heater_watchdog:
            if datetime.datetime.utcnow() - self._last_watchdog_reset > datetime.timedelta(minutes=1):
                try:
                    self._pymach.reset_heater_watchdog()
                except kaiten.error.MachineDriverException as e:
                    if not e.code == kaiten.error.not_ready:
                        raise(e)
                else:
                    self._last_watchdog_reset = datetime.datetime.utcnow()
        status = self._pymach.iterate()
        self._light_manager.update_lights()
        self._set_status_struct(status)
        self._update_machine_info()
        self._update_process_info()
        self._eval_toolhead_error_code()
        self._eval_machine_error_code(status['machine_error'])

    def _update_machine_info(self):
        """
        Updates the machine info with various tidbits of information about the
        machine.  The machine contains location, temperature, etc.  We need to
        decide what info we want from the machine.
        """
        self._system_info["disabled_errors"] = [
            kaiten.error.error_to_string[e] for e in self._disabled_toolhead_errors]
        self._system_info["sound"] = self._config['kaiten']['sound']
        self._system_info["auto_unload"] = self._config['kaiten']['auto_unload']

    def _update_process_info(self):
        """
        Updates the machine with information about the process.  The process
        decides what information it gives us.
        """
        if self._current_process is None:
            self._system_info["current_process"] = None
        else:
            self._system_info["current_process"] = self._current_process.get_info_dict()

    def _iterate_process(self):
        """
        Executes another iteration of a process
        We evict the process if we get a StopIteration error.
        """
        result = kaiten.error.ok
        process = self._current_process
        try:
            # _current_process is set to None if the process is force
            # canceled. If this is the case, manually raise StopIteration
            # so the process generator is properly evicted.
            if process is None:
                raise StopIteration
            result = next(process.tasklets)
        except StopIteration as e:
            result = kaiten.error.stop_iteration
            self._log.info("Process Finished: %r", process)
            self._evict_process(process)
            raise e
        # We handle All python exceptions (except StopIteration) in this way
        except Exception as e:
            # Handle python errors in this special way to include some
            # additional metadata
            self._handle_python_exception(e)
        else:
            self._eval_machine_error_code(result)

    def contract_duration(self):
        return datetime.timedelta(0, 0, 0, 500)

    def expected_run_time(self):
        if self._current_process:
            return self._current_process.expected_run_time()
        else:
            return datetime.timedelta(seconds=kaiten.constants.normal_generator_time)

    def register_process(self, process):
        """
        Appends a process to the list of currently running processes.  All of the
        checking for if this process can actually be run is done in the
        "register_process" decorator.

        @param process: Process to register
        """
        # We want to clear out toolhead errors when we register a new process
        self.clear_toolhead_error_memory()
        self._log.info("Registering new process %r" % (process))
        self._current_process = process
        self._register_callback(process)
        self._last_running_process = process
        self.state_notification()

    def _force_evict_process(self, process):
        """
        @param process: Process to force to evict

        Similar to evict_process, but calls force_cancel first
        """
        process.force_cancel()
        self._evict_process(process)

    def _evict_process(self, process):
        """
        @param process: Process to evict
        """
        # We issue done here to make sure all connected clients get the
        # done notifications
        self._log.info("Evicting process %r", process)
        self._current_process = None
        self.state_notification()
        for index in self._extruders_changed_during_process:
            self._notify_extruder_change(index, only_uncalibrated=True)
        self._extruders_changed_during_process = set()

    def _cancel_process(self, error_dict=None):
        """
        Cancels the current process.

        We can raise a ProcessNotCancellableException if either the process
        is immutable OR the process has already been cancelled.
        """
        process = self._current_process
        if process is None or not process.is_cancellable():
            raise kaiten.error.ProcessNotCancellableException
        else:
            self._log.info("Cancelling process %s", process)
            process.cancel(error_dict)

    @kaiten.decorator.pass_client
    @kaiten.decorator.jsonrpc
    def process_method(self, method:str, params:dict=None, client=None) -> None:
        """
        This function calls a method on the current process.

        Certain process have callable methods, that are advertised in
        their callable_methods dict. These methods should NOT be generators
        and should return quickly.

        @context: As long as there is a active process

        @param method: Method name to call on the current process
        @param params: Params to be passed to the method being called
        """
        self._process_method_client = client
        params = params or {}
        if self._current_process:
            self._current_process.process_method(method, params)
        else:
            self._log.info("No process running for process_method {0}".format(method))
            raise kaiten.error.ProcessMethodNotCallableException

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.enforce_types
    def set_auto_unload(self, unload_case:str) -> None:
        """
        Sets when should the auto-unload happen when a print is done

        @param unload_case: Auto-unload on successful, failed, and 
            cancelled prints due to error when "all prints", only on
            successful when "successful prints" and never when "off".
        """
        unload_case = unload_case.lower()
        self._server.mixpanel_event("set_auto_unload",
                                    current_setting=self._config["kaiten"]["auto_unload"],
                                    new_setting=unload_case)
        if unload_case in mbcoreutils.common_settings.auto_unload_cases:
            self._server.update_home_config({"auto_unload": unload_case})
            self._log.info("setting auto-unload to {0}".format(unload_case))
        else:
            self._log.error("Ignoring client attempting to set auto-unload to {0}".format(unload_case))

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.enforce_types
    def toggle_sound(self, state:bool) -> None:
        """
        Enables or disables the bots sound depending on the state passed in.

        @param state: If True the bot will make sound, if False it will not.
        """
        self._server.mixpanel_event("toggle_sound",
                                    current_setting=self.get_sound_state(),
                                    new_setting=state)
        self._server.update_home_config({"sound": state})

    @kaiten.decorator.jsonrpc
    def get_sound_state(self) -> bool:
        """
        Returns the current sound state.

        @context: This can be invoked in whatever context

        @return bool: If True, sound is enabled. If False, sound is disabled.
        """
        return self._config['kaiten']['sound']

    @kaiten.decorator.jsonrpc
    def get_tool_usage_stats(self) -> dict:
        """
        Returns a dictionary containing the usage stats for the connected tool.

        @context: This can be invoked in any context. However, be aware that stats
                  are only updated at the end of a print; the ones returned
                  are cached in the machine driver.

        @return dict: A dict containing the usage statistics for the tool, as
                      specified here:

                      {"retract_count" : int,
                       "extrusion_time_s": int,
                       "extrusion_distance_mm" : int,
                       "serial": int,
                       "extrusion_mass_g": float }
        """
        stats = self._pymach.get_cached_tool_usage_stats(0)
        self._log.info("Finding stats {0}".format(stats))
        d = self._config['linear_density']
        stats['extrusion_mass_g'] = stats['extrusion_distance_mm'] * d
        return stats

    @kaiten.decorator.jsonrpc
    def get_available_z_offset_adjustment(self) -> float:
        """
        Returns the maximum user z offset that can be set

        Note that this is a maximum for the magnitude of the z offset, so a
        value of 0.5 would mean that any value between -0.5 and 0.5 is okay.

        @context: This can be invoked in whatever context

        @return: The maximum user z offset that can be set
        """
        return self._config["home"]["available_z_offset_adjustment"]

    @kaiten.decorator.jsonrpc
    def get_z_adjusted_offset(self) -> float:
        """
        Returns the current user z offset

        @context: This can be invoked in whatever context

        @return: The current user z offset that can be set
        """
        return self._config['kaiten']['z_adjusted_offset']

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.enforce_types
    def set_z_adjusted_offset(self, offset:float) -> None:
        """
        Set the current user z offset

        @param offset: The offset to set
        """
        self._server.update_home_config({"z_adjusted_offset": offset})

    @kaiten.decorator.jsonrpc
    def has_z_calibration_routine(self) -> bool:
        """
        Returns whether Z Calibration can be run on this bot

        @return: True if the bot has a Z calibration routine
        """
        if self._config["home"]["z_calibration_type"]=="None":
            return False
        else:
            return True

    @kaiten.decorator.jsonrpc
    def is_endstop_triggered(self) -> bool:
        """
        Returns whether the Z endstop is currently triggered

        @context: Only for bots which actually have a z endstop

        @return: Whether the Z endstop is currently triggered
        """
        return self._pymach.endstop_triggered(2)

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.enforce_types
    def set_toolhead_error_visibility(self, error:str, ignored:bool) -> None:
        """
        Function to make a toolhead error visible or invisible.

        If ignored is true, the toolhead error specified will never be passed to
        anything from the machine manager. It will behave in all respects as if
        it never happened.

        @param error: Name of the error we wish to affect.
        @param ignored: If True the error specified will be ignored going forward,
        """
        disabled_errors = self._config["kaiten"]["disabled_errors"]
        if ignored:
            if error not in disabled_errors:
                disabled_errors.append(error)
        else:
            if error in disabled_errors:
                disabled_errors.remove(error)
        self._server.update_home_config({"disabled_errors": disabled_errors})

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def download_and_install_firmware(self) -> dict:
        """
        Downloads firmware file from server (if not already downloaded)
        and uploads firmware to the birdwing machine.  This will install
        whatever firmware a firware_updates_info_change last reported.

        This process takes a rather long time, and ends with restarting
        the printer.  Clients should therefore expect that their
        connection will drop before the process completes.

        @context: This shouldn't be attempted whilst any other processes are
                  running.

        @return dict: Status dict
        """
        process = kaiten.processes.FirmwareBurningProcess(
            self, self._pymach, self._config,
            firmware_updates=self._server.firmware_updates)
        return process

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def brooklyn_upload(self, filepath:str, transfer_wait:bool=False) -> dict:
        """
        Uploads firmware to the birdwing machine.

        This process takes a rather long time, and ends with restarting
        the printer.  Clients should therefore expect that their
        connection will drop before the process completes.

        @context: This shouldn't be attempted whilst any other processes are
                  running.

        @param filepath: Path to the firmwware zip file, should be under /home/
                         by default or whatever kaiten.constants.home_dir is.
        @param transfer_wait: True if we are transferring after starting the
                              upload. False if the firmware file is already
                              in place.
        @return dict: Status dict
        """
        # Gotta strip the left / we can join the path later on
        filepath = filepath.lstrip("/")
        filepath = os.path.join(kaiten.constants.home_dir, filepath)
        if not transfer_wait and not os.path.exists(filepath):
            self._log.info("Cant find file %s", filepath)
            raise FileNotFoundError
        else:
            process = kaiten.processes.FirmwareBurningProcess(self, self._pymach,
                        self._config, filepath, transfer_wait)
            return process

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def run_diagnostics(self, tests:list) -> dict:
        """
        Creates a diagnostics process

        @context: This should not be run whilst any other process is running.

        @param tests: list of tests describing the tests to run.
            Currently we support:
                * bronx
                * brooklyn
                * lcd
                * chamber
        @return: Returns a dict containing the results for the diagnostic tests
        """
        process = kaiten.processes.DiagnosticProcess(self, self._pymach,
                                                     tests, self._config)
        return process

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.pass_client
    @kaiten.decorator.register_process
    def print(self, filepath:str, ensure_build_plate_clear:bool=None,
              client=None, transfer_wait:bool=False) -> dict:
        """
        Creates a print process which will begin printing the file.

        We use the register_process decorator to register the process.

        @context: Should be called if the bot is idle. Assumes the print
                  is already accessable on this filesystem.

        @param filepath: Filepath to print
        @param ensure_build_plate_clear: optional bool that overrides any other logic
                                         determining whether to show a
                                         clear build plate dialog prior to starting
                                         a print.
        @param transfer_wait: Print process waits for file transfer when flag is set.
        @return dict: Status dict
        """
        return self._print(filepath, client, 
                           ensure_build_plate_clear=ensure_build_plate_clear,
                           transfer_wait=transfer_wait)

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.pass_client
    @kaiten.decorator.register_process
    def drm_print(self, layout_id:int, client=None) -> dict:
        """
        Print a file from a drm print server

        Creates a print process which will begin printing a layout from a
        remote host and register it with the register_process decorator.

        @context: Should be called if the bot is idle and
                  connected to the internet

        @param layout_id: ID of the layout to print

        @return dict: Status dict
        """
        return self._print(None, client, layout_id, stream=True)

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.pass_client
    @kaiten.decorator.register_process
    def library_print(self, layout_id:int, client=None) -> dict:
        """
        Print a file from the cloud library

        Creates a print process which will begin printing a layout from a
        remote host and register it with the register_process decorator.

        @context: Should be called if the bot is idle and
                  connected to the internet

        @param layout_id: ID of the layout to print

        @return dict: Status dict
        """
        return self._print(None, client, layout_id)

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.pass_client
    @kaiten.decorator.register_process
    def cloud_slice_print(self, url:str, client=None, ensure_build_plate_clear:bool=None) -> dict:
        """
        Print a file from a cloud slice url

        Creates a print process which will download (and print) a .makerbot file
        from cloud slicer once it's done slicing

        @context: Should be called if the bot is idle and
                  connected to the internet

        @param url: URL to receive slice status
        @param ensure_build_plate_clear: optional bool that overrides any other logic
                                         determining whether to show a
                                         clear build plate dialog prior to starting
                                         a print.
        @return dict: Status dict
        """
        return self._print(None, client, url=url, ensure_build_plate_clear=ensure_build_plate_clear, cloud_slice=True)

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.pass_client
    @kaiten.decorator.register_process
    def external_print(self, url:str, client=None, ensure_build_plate_clear:bool=None) -> dict:
        """
        Print a file from an external url

        Creates a print process which will download a .makerbot file from a
        remote host and begin printing it

        @context: Should be called if the bot is idle and
                  connected to the internet

        @param url: Full external path to .makerbot file
        @param ensure_build_plate_clear: optional bool that overrides any other logic
                                         determining whether to show a
                                         clear build plate dialog prior to starting
                                         a print.
        @return dict: Status dict
        """
        return self._print(None, client, url=url, ensure_build_plate_clear=ensure_build_plate_clear)

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.pass_client
    @kaiten.decorator.register_process
    def print_again(self, client=None) -> dict:
        """
        Creates a print process using the print inside the last_print_dir.

        If no files are in the last_print_dir folder, we raise an exception.

        @context: Should be run after a print has been run, otherwise it won't
                  have a print to print again

        @return dict: Status dict
        """
        current_print_dir = kaiten.constants.current_print_dir
        last_print_dir = kaiten.constants.last_print_dir
        os.makedirs(last_print_dir, exist_ok=True)
        try:
            filename = os.listdir(last_print_dir)[0]
            filepath = os.path.join(last_print_dir, filename)
        except IndexError:
            self._log.info("Cant print again, no last thing")
            raise FileNotFoundError
        self._log.info("Printing %s again." % filename)
        os.rename(filepath, os.path.join(current_print_dir, filename))
        return self._print(filename, client)

    def _print(self, filepath:str, client=None, layout_id=None, url=None, stream=False, cloud_slice=False,
               ensure_build_plate_clear=None, transfer_wait=False) -> dict:
        current_print_dir = kaiten.constants.current_print_dir
        last_print_dir = kaiten.constants.last_print_dir
        if filepath is not None:
            filepath = os.path.join(current_print_dir, filepath)
        if transfer_wait:
            self._log.info("Expecting file %s" % filepath)
        if layout_id is None and url is None and not os.path.exists(filepath) and not transfer_wait:
            self._log.info("Cant find file %s" % filepath)
            raise FileNotFoundError
        else:
            if not os.path.exists(last_print_dir):
                os.makedirs(last_print_dir)
            # Clear last_print_dir before starting the current print
            for f in os.listdir(last_print_dir):
                os.remove(os.path.join(last_print_dir, f))
            args = (self, self._pymach, self._libparser, filepath,
                    self._config, client)
            if layout_id and stream:
                process = kaiten.processes.DRMPrintProcess(*args, layout_id=layout_id)
            elif layout_id:
                process = kaiten.processes.LibraryPrintProcess(*args, layout_id=layout_id)
            elif cloud_slice and url:
                process = kaiten.processes.CloudSlicePrintProcess(*args, url=url, ensure_build_plate_clear=ensure_build_plate_clear)
            elif url:
                process = kaiten.processes.ExternalPrintProcess(*args, url=url, ensure_build_plate_clear=ensure_build_plate_clear)
            else:
                process = kaiten.processes.PrintProcess(*args, 
                              ensure_build_plate_clear=ensure_build_plate_clear,
                              transfer_wait=transfer_wait)
            return process

    def _pymach_blacklist_check(self, machine_func):
        """
        Raise an exception when calling unsafe pymachine methods from the API

        Allowing some pymachine methods to be invoked with arbitrary arguments
        by any user with authorized access to the kaiten API is equivalent to
        granting arbitrary code execution to these users.  We aim to at least
        limit this to authorized users who are also on the same local network
        as the printer and hopefully someday we will put in place more limits
        on this as well.  So we refuse to allow API access to these specific
        pymachine methods.
        """
        blacklist = [
            'destroy_parser_interface',
        ]
        if machine_func in blacklist:
            raise JsonRpcException(33, 'Pymachine method not allowed')

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def machine_action_command(self, machine_func:str, params:list,
                               name:str=None, ignore_tool_errors:bool=False) -> dict:
        """
        Process that executes a command against the pymachine object.

        If the queue is open, we will instead add the passed in func/params to
        the queue to be later executed with "execute_queue".

        @context: Should only be called if the bot is idle, or if a queue is open

        @param machine_func: String name of the function on the pymachine object.
        @param params: Dict of {str: value} representing the params of the pymachine
            function.
        @param name: What to report this process as instead of 'MachineActionProcess'
        @param ignore_tool_errors: If set, ignore ALL tool errors
        @return dict: Status dict
        """
        self._pymach_blacklist_check(machine_func)
        if self._queue_open:
            self._queue.append((machine_func, params))
            return True
        else:
            process = kaiten.processes.MachineActionProcess(self,
                                                            self._pymach,
                                                            self._config,
                                                            machine_func,
                                                            params, name=name,
                                                            ignore_tool_errors=ignore_tool_errors)
            return process

    @kaiten.decorator.jsonrpc
    def machine_query_command(self, machine_func:str, params:list,
                              ignore_tool_errors:bool=False) -> object:
        """
        Calls a function on the machine

        @context: Call query commands whenever you want

        @param machine_func: String name of the function on the pymachine object.
        @param params: Dict of {str: value} representing the params of the pymachine
            function.
        @param ignore_tool_errors: Bool, optional. Ignore tool errors.
        @return object: Some sort of state information
        """
        self._pymach_blacklist_check(machine_func)
        return getattr(self._pymach, machine_func)(**params)

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def machine_query_process(self,
                              machine_func:str,
                              params:list,
                              name:str,
                              ignore_tool_errors:bool=False) -> dict:
        """
        Process that executes a command on the pymachine object and puts the
        results in its process_complete status dict.

        @context: Should only be called if the bot is idle.

        @param machine_func: String name of the function on pymachine.
        @param params: Dict of {str: value} representing the params to pass.
        @param name: What to report this process as instead of 'MachineQueryProcess'
        @param ignore_tool_errors Bool, optional. Ignore tool errors.
        @return dict: Status dict
        """
        self._pymach_blacklist_check(machine_func)
        process = kaiten.processes.MachineQueryProcess(self,
                                                       self._pymach,
                                                       self._config,
                                                       machine_func,
                                                       params,
                                                       name=name,
                                                       ignore_tool_errors=ignore_tool_errors)
        return process

    @kaiten.decorator.jsonrpc
    def open_queue(self, clear:bool) -> None:
        """
        Opens the move queue up for appending.

        @context: Should be called when a user wants to add to the queue

        @param clear: Bool that, if true, will reset the queue.
        """
        self._log.info("Opening Queue")
        self._queue_open = True
        if clear:
            self._queue = []

    @kaiten.decorator.jsonrpc
    def close_queue(self) -> None:
        """
        Closes the movement queue.

        @context: Only makes sense to call this after open_queue has been called
        """
        self._log.info("Closing Queue")
        self._queue_open = False

    @kaiten.decorator.jsonrpc
    def clear_queue(self) -> None:
        """
        Clears the movement queue.

        @context: Should only be run if there is a queue to be cleared
        """
        self._log.info("Clearing Queue")
        self._queue = []

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def execute_queue(self) -> dict:
        """
        Iterates through the queue executing all (machine_func,param) tuples.

        @context: Should be called only after the open_queue() function has been
                  called (and some commands were appended to the queue)

        @return dict: Status dict
        """
        self._log.info("%s Executing Queue")
        process = kaiten.processes.QueueProcess(self,
            self._pymach, self._queue)
        return process

    @kaiten.decorator.jsonrpc
    def get_queue_status(self) -> dict:
        """
        Gets the current status of the movement queue.

        This can potentially be a HUGE amount of information.

        @context: This can be called anytime, but should be kept to a minimum
                  when a intensive process is running (printing)

        @return dict: Dictionary containing the movement queue and whether it is
                      open for appending
        """
        status = {
            'queue': self._queue,
            'queue_open': self._queue_open,
        }
        return status

    def _set_build_plate_check(self, state:bool):
        self._server.update_home_config({"clear_build_plate": state})

    @kaiten.decorator.jsonrpc
    def disable_check_build_plate(self):
        """
        Disable the clear build plate check at the start of prints
        """
        self._set_build_plate_check(False)

    @kaiten.decorator.jsonrpc
    def enable_check_build_plate(self):
        """
        Enabled the clear build plate check at the start of prints
        """
        self._set_build_plate_check(True)


    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def bronx_upload(self, filepath:str, toolhead:int) -> dict:
        """
        Upload a bronx hex file that is on the filesystem to the toolhead board.

        @context: Run anytime if there is a process queue, else only when idle

        @param filepath: Path to the hex file to upload
        @param toolhead: Index of the toolhead to update
        @return dict: Status dict
        """
        return self.get_bronx_upload_process(filepath, toolhead)

    def get_bronx_upload_process(self, filepath, toolhead):
        """
        We allow anonymous bronx upload processes to be run (usually by firmware
        upload)
        """
        return kaiten.processes.BronxUploadProcess(self, self._pymach,
                                                   filepath, toolhead,
                                                   self._config)

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def preheat(self, temperature_settings:list=None) -> dict:
        """
        Preheat function to heat the machine's heaters to a specified target.
        The process will not wait for the target to be reached, and this
        process will terminate almost immediately.

        @context: Can only be run when the bot is not running a process

        @param temperature_settings: Temperature values to heat up to.
            In the form of [tool_0, tool_1].

        @return dict: Status dict
        """
        process = kaiten.processes.PreheatProcess(self,
            self._pymach, self._config,
            temperature_settings=temperature_settings)
        return process

    @kaiten.decorator.register_process
    @kaiten.decorator.jsonrpc
    def load_filament(self, tool_index:int,
                      temperature_settings:list=None) -> dict:
        """
        Starts the load filament process.

        Will heat the specified tool and move its motor.

        @context: Can only be run when the bot is not running a process

        @param tool_index: Index of the tool that will be loaded
        @param temperature_settings: Temperature values to heat up to. In the form
            of [tool_0, tool_1].
        @return dict: Status dict
        """
        process = kaiten.processes.LoadFilamentProcess(self,
            self._pymach, tool_index, self._config)
        return process

    @kaiten.decorator.register_process
    @kaiten.decorator.jsonrpc
    def unload_filament(self, tool_index:int,
                        temperature_settings:list=None) -> dict:
        """
        Starts the unload filament process.

        Will heat the specified tool and move its motor.

        @context: Can only be run when the bot is not running a process

        @param tool_index: index of the tool we want to unload
        @param temperature_settings: Temperature values to heat up to. In the form
            of [tool_0, tool_1].

        @return dict: Status dict
        """
        process = kaiten.processes.UnloadFilamentProcess(self,
            self._pymach, tool_index, self._config)
        return process

    @kaiten.decorator.register_process
    @kaiten.decorator.jsonrpc
    def setup_printer(self, jump_to_wifi_setup:bool=False) -> dict:
        """
        Starts the printer setup process that is displayed to first-time users

        @context: Can only be run when the bot is not running a process

        @param jump_to_wifi_setup: If True, skip straight to the wifi setup step

        @return dict: Status dict
        """
        process = kaiten.processes.SetupProcess(
            self, self._pymach, self._config,
            jump_to_wifi_setup=jump_to_wifi_setup)
        return process

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def firmware_cleanup(self) -> dict:
        """
        Starts the firmware cleanup process.

        Should be run automagically when kaiten starts up with the
        first_firmware_boot file is present on the filesystem

        @context: Can only be run when the bot is not running a process

        @return dict: Status dict from the FirmwareCleanupProcess
        """
        process = kaiten.processes.FirmwareCleanupProcess(self, self._pymach,
                                                          self._config)
        return process

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def cool(self, ignore_tool_errors:bool=False) -> dict:
        """
        Turns off all heaters on the machine.

        @context: Can only run when the bot is not running a process

        @param ignore_tool_errors: If True errors caused by the tool are ignored
        @return dict: MachineActionProcess status dict
        """
        params = {}
        process = kaiten.processes.MachineActionProcess(self,
            self._pymach, self._config, "cool", params, ignore_tool_errors=ignore_tool_errors)
        return process

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    @kaiten.decorator.send_analytics
    def reset_to_factory(self,
                         clear_calibration:bool=False) -> dict:
        """
        Resets the machine to its factory settings.

        This does not currently cause kaiten to reset.

        @context: Call this when the bot is not busy running another process

        @param clear_calibration: If True the bots calibration settings will be
                                  wiped (defaults to False)
        @return dict: Status dict form the ResetToFactoryProcess
        """
        return kaiten.processes.ResetToFactoryProcess(self, self._pymach,
                                                      self._config, clear_calibration)

    @kaiten.decorator.jsonrpc
    def bot_maintained(self) -> None:
        """
        DEPRECATED: Does nothing
        """
        pass

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def manual_level(self) -> dict:
        """
        Starts the manual leveling process.

        This process is incredibly stateful, and requires a rather long json-rpc
        conversation with the LCD. This function is only relevant for
        the platypus machine.

        @context: Can only be run when the bot it not running another process

        @return dict: Status dict returned by the ManualLevelingProcess
        """
        return kaiten.processes.ManualLevelingProcess(self, self._pymach,
                                                      self._config)

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def assisted_level(self) -> dict:
        """
        Starts the assisted leveling process.

        This process is incredibly stateful, and requires a rather long json-rpc
        conversation with the LCD. This function is only relevant for
        the platypus machine.

        @context: Can only be run when there are no other active process

        @return dict: Status dict returned by the AssitedLevelingProcess
        """
        return kaiten.processes.AssistedLevelingProcess(self, self._pymach,
            self._config)

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def calibrate_z_offset(self) -> dict:
        """
        Calibrate the offset between the plate and a reference point.

        Stores an offset between the actual build plate position and a reference
        point that can be homed to with a hot extruder.

        @context: Can run when the bot has no other active processes

        @return dict: Status dict of the ZCalibratoinProcess
        """
        return kaiten.processes.ZCalibrationProcess(self, self._pymach,
                                                    self._config)

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def home(self, axes:list, preheat:bool=False) -> dict:
        """
        Homes the given axes of this machine

        @context: Can run when no other process is running

        @param axes: List of character names to home (i.e ['x','z']
        @param preheat: Not used
        @return dict: Status dict from the HomingProcess
        """
        return kaiten.processes.HomingProcess(self, self._pymach,
                                              axes, self._config)


    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def zip_logs(self, zip_path:str) -> dict:
        """
        Zips all of the logs to specific zip path

        @context: Can run when the bot is not running a process

        @param zip_path: Path where the zip file will be created
        @return dict: Status dict for the ZipLogsProcess
        """
        return kaiten.processes.ZipLogsProcess(self, self._pymach, zip_path)

    @kaiten.decorator.jsonrpc
    def copy_ssh_id(self, filepath:str=
                    os.path.join(kaiten.constants.home_dir, 'usb_storage/id_rsa.pub')):
        """
        Copy a given SSH ID

        @context: Can run any time

        @param filepath: Filepath of the SSH public id to use.
        """
        # This could probably use some cleanup, and also probably doesn't
        # belong in machine_manager
        try:
            with open(filepath, 'r') as idfile:
                identity = idfile.read()
        except FileNotFoundError:
            self._log.error("Couldn't open ssh id file %s"% filepath)
            raise JsonRpcException(46, "Open for read failure", filepath)
        yield
        os.makedirs('/var/ssh', exist_ok=True)
        with open('/var/ssh/authorized_keys', 'a') as keys:
            keys.write(identity+'\n')
        if not os.path.exists('/tmp/sshd.pid'):
            import subprocess
            p = subprocess.Popen(['/etc/init.d/S50sshd', 'start'])
            # No need to wait around for this to finish

    @kaiten.decorator.jsonrpc
    def clear_ssh_id(self, filepath:str=None):
        """
        Clear out SSH IDs.

        By default this removes all SSH IDs.  This can also read an SSH ID
        from a given filepath and delete only that ID.

        @context: Can run any time

        @param filepath: Filepath of a single SSH public id to clear
        """
        # This could probably use some cleanup, and also probably doesn't
        # belong in machine_manager.  I am not at all convinced that the
        # removal of a single ssh id actually works.
        if None is filepath:
            self._log.info("Deleting all SSH IDs")
            open('/var/ssh/authorized_keys', 'w').close()
        else:
            try:
                with open(filepath, 'r') as idfile:
                    ssh_id = idfile.read()
            except FileNotFoundError:
                self._log.error("Couldn't open ssh id file %s"% filepath)
                raise JsonRpcException(46, "Open for read failure", filepath)
            self._log.info("filepath given, deleting id {0}".format(ssh_id))
            keys = []
            with open('/var/ssh/authorized_keys', 'r') as keysfile:
                for line in keysfile:
                    if line != ssh_id:
                        keys.append(line)
                    else:
                        self._log.info("found key, deleting")
            with open('/var/ssh/authorized_keys', 'w') as keysfile:
                for line in keys:
                    keysfile.write(line+'\n')

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def yonkers_upload(self, filepath:str,
                       uid:str, index:int,
                       force:bool=False, id:int=None) -> dict:
        """
        Update the yonkers EEPROM.

        Parses a .json file specified by the filepath param and uploads it to
        the yonkers board to a tool at the specified index.

        @context: Should only be called when the bot is not running a process

        @param filepath: Path to the JSON file to use for the upload
        @param uid: Unique ID to assign to the Yonkers
        @param index: Index of the toolhead whose Yonkers will be uploaded to
        @param force: The upload process will ignore all pre-upload checks (tool compatibility, etc.)
        @param id: If given, overwrite the toolhead id (version)
        @return dict: Status dict of the YonkersUploadProcess
        """
        return self.get_yonkers_upload_process(filepath, uid, index, force, id)

    def get_yonkers_upload_process(self, filepath, uid, index, force, id):
        """
        Yonkers processes can be run annonymously (usually by upload_firmware)
        """
        return kaiten.processes.YonkersUploadProcess(self, self._pymach,
                                                     filepath, uid, index,
                                                     force, id)

    @kaiten.decorator.register_process
    @kaiten.decorator.jsonrpc
    def program_tool(self, index:int, filepath:str, id:int,
                     uid=0, force=False) -> dict:
        """
        Generic program tool method that will work on any machine.
        Raises UnrecognizedToolError if the machine does not support the tool.

        @INTERNAL

        @param index The index to program.
        @param filepath The path (on the machine) to the firmware file. The type
        of this file is different depending on the tool type to program. It is
        a binary file for a mk14, and a json file for mk13 and previous.
        @param id The tool id to program.
        @param uid A unique ID to give the tool
        @param force Whether to force an update to change the type of a
        currently connected tool.
        @return The process info dict.
        """
        tool_type = mbcoreutils.tool_mappings.Tool.from_id(id).type
        if tool_type not in self._config['extruder_profiles'].keys():
            raise kaiten.error.UnrecognizedToolError(tool_type)
        self._log.info("Programming tool {}".format(tool_type))
        if tool_type == 'mk14':
            params = {'index': index, 'path': filepath}
            return kaiten.processes.MachineActionProcess(self,
                                                         self._pymach,
                                                         self._config,
                                                         'program_tool',
                                                         params)
        else:
            return get_yonkers_upload_process(self, filepath, uid, index, force,
                                              id)
            
            
    @kaiten.decorator.register_process
    @kaiten.decorator.jsonrpc
    def set_z_pause_mm(self, z_pause_mm:int) -> dict:
        """
        Sets a specific Z pause height to stop the machine at.

        The machine will go into the suspended state when this happens.
        The user must tell the machine to continue printing to resume.

        @context: Should only be called when the bot is not running a process

        @param z_pause_mm: Z height (in mm) we want the bot to suspend at
        @return dict: Status dict from teh MachineActionProcess
        """
        params = {
            "z_pause_mm": z_pause_mm}
        process = kaiten.processes.MachineActionProcess(self,
            self._pymach, self._config, "set_z_pause_mm", params)
        return process

    @kaiten.decorator.register_process
    @kaiten.decorator.jsonrpc
    def clear_z_pause_mm(self, z_pause_mm:int) -> dict:
        """
        Clears a specific value from the machine's list of Z pause locations.

        @context: Should only be called when the bot is not running a process

        @param z_pause_mm: Z pause height (in mm) we want to clear
        @return dict: Status dict from the MachineActionProcess
        """
        params = {
            "z_pause_mm": z_pause_mm
        }
        process = kaiten.processes.MachineActionProcess(self, self._pymach,
                                                        self._config,
                                                        "clear_z_pause_mm",
                                                        params)
        return process

    @kaiten.decorator.register_process
    @kaiten.decorator.jsonrpc
    def clear_all_z_pause(self) -> dict:
        """
        Clears all Z Pause values from the machine's list of locations.

        @context: Should only be called when the bot is not running a process

        @return dict: Status dict of the MachineActionProcess
        """
        process = kaiten.processes.MachineActionProcess(self, self._pymach,
                                                        self._config,
                                                        "clear_all_z_pause", {})
        return process

    @kaiten.decorator.jsonrpc
    def enable_z_pause(self) -> dict:
        """
        Enables Z pausing on the machine.

        @context: Should only be called when the bot is not running a process

        @return dict: Status dict of the MachineActionProcess
        """
        return self.machine_action_command("enable_z_pause", {},
            name="EnableZPause")

    @kaiten.decorator.jsonrpc
    def disable_z_pause(self) -> dict:
        """
        Disables Z pausing on the machine.

        @context: Should only be called when the bot is not running a process

        @return dict: Status dict of the MachineActionProcess
        """
        return self.machine_action_command("disable_z_pause", {},
            name="DisableZPause")

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def park(self) -> dict:
        """
        Moves the bot to it's parked position.

        @context: Shouldn't be called when the bot is moving, or whilst another
                  process is running.

        @return dict: Status dict of the ParkProcess
        """
        self._log.info('Parking')
        process = kaiten.processes.ParkProcess(self, self._pymach,
                                               self._config)
        return process

    @kaiten.decorator.jsonrpc
    def cancel(self, force:bool=False) -> None:
        """
        JsonRPC exposed function to cancel the current process.

        @context: Can be called if there is a _current_process

        @param force: If True the process will be removed from the process dict.
                      This WILL NOT ABORT the machine
                      (so whatever is buffered is buffered), and is only meant
                      to be a developer option when processes are not returning.
        """
        if force:
            self._log.info("Forcibly cancelling process")
            self._current_process = None
        else:
            self._cancel_process()


    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def load_print_tool(self, index:int) -> dict:
        """
        A process that will help a user load a print tool.

        It spins the motors bit by bit, helping to lock the castle gears into place.

        @context: Can be called if the bot is idle

        @param index: Index of the toolhead we want to load a print tool
        @return dict: Status dict for the MachineActionProcess
        """
        machine_func = "connect_tool"
        params = {"index": index,
                  'abort_toolhead_only': False}
        return kaiten.processes.MachineActionProcess(self, self._pymach,
                                                     self._config,
            machine_func, params, name="LoadPrintTool",
            ignore_tool_errors=True)

    @kaiten.decorator.raise_priv
    @kaiten.decorator.jsonrpc
    def resume_boot(self) -> None:
        """
        Resumes the boot after kaiten/printerpanel are booted

        Less critical init scripts are paused for a fixed time period
        while kaiten and printerpanel start up.  Call this to resume
        the scripts immediately.

        @context: This should be called once kaiten and printerpanel are init'd
        """
        self._log.info("Resuming boot sequence")
        try:
            with open('/tmp/wait.pid', 'r') as f:
                pid = f.read().strip()
            import signal
            os.kill(int(pid), signal.SIGALRM)
        except Exception as e:
            self._log.info("Failed to resume boot sequence")
            pass

    @kaiten.decorator.jsonrpc
    def acknowledged(self, error_id:int=None) -> None:
        """
        Acknowledges an error state in kaiten.

        @context: This should be called when the bot is in an error state

        @param error_id: ID of the error we will acknowledge
        """
        self._log.info("Acknowledging error state in kaiten (error id %s)" % str(error_id))
        if error_id is not None: # not all clients send error_id back
            self._error_acknowledged(error_id)
        #Pop the error light state here
        self.pop_error_light_state()

    @kaiten.decorator.jsonrpc
    def get_statistics(self) -> dict:
        """
        DEPRECATED -- returns an empty dict

        @return dict: (empty)
        """
        return {}

    @kaiten.decorator.jsonrpc
    def get_persistent_statistics(self) -> dict:
        """
        DEPRECATED -- returns an empty dict

        @return dict: (empty)
        """
        return {}

    @kaiten.decorator.jsonrpc
    def get_print_history(self) -> dict:
        """
        DEPRECATED -- returns an empty dict

        @return dict: (empty)
        """
        return {}

    @kaiten.decorator.raise_priv
    @kaiten.decorator.jsonrpc
    @kaiten.decorator.send_analytics
    def kill_power(self) -> None:
        """
        Attempt to safely power off

        @context: This is 'safe' to call whenever, but it will cause any current
                  process to cease since the bot will shutdown. Use are your own
                  risk.
        """
        import subprocess

        # This is an unfortunate hack because I don't know how to get busybox
        # to execute different shutdown commands for halt and reboot.  Instead
        # busybox will always try to send a poweroff signal to the power IC
        # but it will only succeed if we have first configured the TTY.
        subprocess.check_call(["stty", "-F", "/dev/ttyS2", "9600", "raw"])

        # Either halt or reboot will work here, but reboot will make it more
        # obvious if we failed to talk to the power IC.
        subprocess.check_call("reboot")

    @kaiten.decorator.raise_priv
    @kaiten.decorator.jsonrpc
    def reboot(self) -> None:
        """
        Attempt to safely reboot via the systems 'reboot' command

        @context: This is 'safe' to call whenever, but it will cause any current
                  process to cease since the bot will reboot. So, use at your
                  own risk.
        """
        import subprocess
        subprocess.check_call("reboot")

    @kaiten.decorator.jsonrpc
    def disable_leds(self, disable_knob:bool=False, disable_chamber:bool=False):
        """
        Disable the LEDs specific

        @param disable_knob bool: If True the knob will be disabled from being
            set and it will be turned off
        @param disable_chamber bool: Smae as above, except for the chamber LED
        """
        self._light_manager.disable_lights(disable_knob, disable_chamber)

    @kaiten.decorator.jsonrpc
    def enable_leds(self, enable_knob:bool=False, enable_chamber:bool=False):
        """
        Enable the LEDs specific

        @param enable_knob bool: If True will enable the knob LED and turn it
            on (setting it to the correct state color)
        @param enable_chamber bool: Same as above except for the chamber LED
        """
        self._light_manager.enable_lights(enable_knob, enable_chamber)

    @kaiten.decorator.raise_priv
    @kaiten.decorator.jsonrpc
    def reset_lcd(self) -> None:
        """
        Reset the lcd, which can clear disco/white screen

        @context: This should only be used if the LCD is showing an issue with
                  the screen.
        """
        f = open("/sys/class/graphics/fb0/blank", "w")
        f.write("4")
        f.close()

        f = open("/sys/class/graphics/fb0/blank", "w")
        f.write("0")
        f.close()

    @kaiten.decorator.jsonrpc
    def toggle_lcd(self, on:bool=True) -> None:
        """
        Toggle the LCD power

        @INTERNAL

        @param on: True powers on the LCD, False powers it off
        """
        f = open("/sys/class/graphics/fb0/blank", "w")
        if on:
            f.write("0")
        else:
            f.write("4")
        f.close()

    @kaiten.decorator.contractify(interval=0.1)
    @kaiten.decorator.jsonrpc
    def wifi_signal_strength(self, ssid:str, iface:str) -> int:
        """
        Tests the strength of a wifi network via the specific interface.

        @context: Used for testing wifi functionality on the assembly line.
                  This can be called any time without issue.

        @param ssid: SSID of the network we will test against
        @param iface: interface we wish to test (usually wlan0)
        @return int: strength of the tested wifi network dBm(Decibel-milliwatts)
                or an error code
                Note: Valid return values are negative
                Error codes are positive
                1000 = network not found
                2000 = more than one network with same name
        """
        import subprocess

        # Bring wifi up, should have no effect if i/f is already up
        ifup_cmd = ['ifconfig', iface, 'up']
        yield from kaiten.util.subprocess_call(ifup_cmd)

        # Scan will occasionally return stale data if it happens
        # too soon after interface wake up
        # TODO: this still gives stale data sometimes...
        yield from kaiten.util.sleep(1)

        # Scan for the requested network
        scan_cmd = ['iw', iface, 'scan', 'ssid', ssid]
        output = yield from kaiten.util.subprocess_get_output(scan_cmd)
        output_lines = output.strip().split("\n")

        # Scrub out tab characters
        output_lines = map(lambda line: line.strip('\t'), output_lines)

        # Get a list of value pairs
        ap_start_str = "(on %s)"% iface
        ap_list = []
        for line in output_lines:
            if ap_start_str in line:
                ap_list.append([])
            if ap_list:
                ap_list[-1].append(line)

        # Convert key-value strings into an actual dict
        def make_wifi_dict(ap):
            wifi_dict = {}
            for line in ap:
                if ap_start_str in line:
                    # The first line is formatted strangely
                    items = line.rstrip(ap_start_str).split(" ")
                else:
                    # The standard format is key: value
                    items = line.split(": ")

                if len(items) == 2:
                    # Standard key: value format
                    wifi_dict[items[0]] = items[1]
                else:
                    # Strange format that we don't care about
                    wifi_dict[items[0]] = ""
            return wifi_dict
        ap_list = map(make_wifi_dict, ap_list)

        # Sometimes iw gives us SSID's that we did not ask for...
        ap_list = list(filter(lambda ap: ap['SSID'] == ssid, ap_list))

        # Nothing doing unless we have exactly one AP...
        if not ap_list:
            self._log.info("Could not locate network '%s'"% ssid)
            return 1000
        elif len(ap_list) > 1:
            self._log.info("More than one network called %s found"% ssid)
            return 2000

        # Signal strength is a string, e.g. -60.0dBm,
        # but we want to return an int
        strength = ap_list[0]["signal"]
        return int(float(strength.strip(" dBm")))

    def fill_config_skeleton(self, skeleton, data):
        """
        Update the values in skeleton without changing any keys.

        This uses certain keys to expand into a list (for instance, for all
        supported extruder types). So it's really only useful for machine
        config.
        """
        new_dict = {}
        supported_types = set(self._config['extruder_profiles'])
        supported_extruders = {mbcoreutils.tool_mappings.invalid_tool.id : None}
        for tool in mbcoreutils.tool_mappings.valid_tools:
            if tool.type in supported_types:
                supported_extruders[tool.id] = tool.type

        override_mappings = {
            'supported_extruders': supported_extruders,
            'attached_extruders': [self.get_extruder_config(i)
                                   for i in range(self.count_extruders())],
            'chamber_temperature_default': self._config['toolheads']\
                                           .get('chamber',
                                                {'heater':{
                                                    'print_temperature_default':
                                                    'erase'}})\
                                           ['heater']['print_temperature_default']
        }
        for key in skeleton.keys():
            if key == '*':
                # This is a wild card that means to operate on every key at this
                # dict level in the data dict.
                for data_key in data.keys():
                    if data_key != 'unknown':
                        new_dict[data_key] = self.fill_config_skeleton(skeleton[key],
                                                                       data[data_key])
            elif key in override_mappings.keys():
                if override_mappings[key] != 'erase':
                    new_dict[key] = override_mappings[key]
                else:
                    self._log.info("override key {0} erased".format(key))
            elif isinstance(skeleton[key], dict):
                new_dict[key] = self.fill_config_skeleton(skeleton[key],
                                                          data[key])
            elif None is skeleton[key]:
                new_dict[key] = data[key]
            else:
                new_dict[key] = skeleton[key]
            # if there is non-dict data in the skeleton, it is static
            # and should not be overridden
        return new_dict

    @kaiten.decorator.jsonrpc
    @kaiten.decorator.register_process
    def wifi_setup(self) -> dict:
        """
        Initiate a process to connect the machine to a wireless network.

        The process manages will scan for WiFi APs, then broadcast a tether
        named with the machine serial. Clients may connect to the tether,
        query the system information for available APs, and then request the
        process to connect to a given AP.

        @return: The process.
        """
        if not self._server.dbus_manager:
            raise kaiten.error.ConfigValueError("dbus must be enabled for wifi setup")
        return kaiten.processes.WifiSetupProcess(self,
                                                 self._pymach,
                                                 self._config,
                                                 self._server.dbus_manager)

    @kaiten.decorator.jsonrpc
    def get_machine_config(self) -> dict:
        """
        Get the machine config settings.

        @return: The machine config settings
        """
        # Lets start (kind of) formatting this according to the spec
        with open(kaiten.constants.machine_config_skeleton_path, 'rb') as f:
            config_skeleton = json.loads(f.read().decode('UTF-8'))
        machine_config = self.fill_config_skeleton(config_skeleton, self._config)
        return machine_config

    def _tool_calibrated(self, index):
        """
        Check if the currently attched tool is calibrated

        Only returns False if we have a tool that should be calibrated (returns
        True when no tool is attached or we don't support tool calibration).
        """
        home_config = self._config["home"]
        if home_config['z_calibration_type'] != 'endstop':
            return True
        try:
            tool_uid = self._pymach.get_tool_uid(index)
            if not tool_uid:
                return True
            tool_home_config = home_config['per_extruder'][str(tool_uid)]
            tool_home_config['z_reference_point']['offset']
            return True
        except KeyError:
            return False

    def get_extruder_config(self, index):
        """
        Return a description of the current attached extruder that
        conforms to the bot config spec.
        """
        return {
            'id': self.configured_tools[index].id,
            'calibrated': self._tool_calibrated(index),
        }

    @kaiten.decorator.jsonrpc
    def dump_machine_config(self, path:str) -> None:
        """
        Copy the machine config dict to a path on the USB storage.

        @context: Used to copy machine config to USB. This method may
        be called at any time (though if there is no USB storage
        connected it will raise an exception).

        @param path: Path, relative to the USB drive root, to copy to.

        If path is a directory, the config will be dumped in that
        directory as machine_config.json.
        If path is empty, the file will be dumped in the USB storage
        root as machine_config.json.
        """
        machine_config = self.get_machine_config()
        path = kaiten.util.chroot_path(
            os.path.join(kaiten.constants.home_dir, 'usb_storage'), path)
        if os.path.isdir(path):
            path = os.path.join(path, 'machine_config.json')
        self._log.info("Storing machine config to %s", path)
        try:
            kaiten.util.write_json_file(path, machine_config)
        except OSError as e:
            # TODO If the USB drive ran out of space (errno == errno.ENOSPC), we
            # should let PP know, but not right now (not user facing currently).
            raise e
