import errno
import json
import logging
import io
import os
import select
import socket
import ssl
import sys
import types


import kaiten.constants
import kaiten.decorator
import kaiten.error
import kaiten.json_reader
import kaiten.log

# We use this a lot in this file and it make lines annoyingly long
fn_attrs = kaiten.decorator.FunctionAttributes

def install(jsonrpc, obj, priv=None):
    """
    Installs all callable components of obj that have been decorated with
    kaiten.decorator.jsonrpc.  We have intentionally avoided inspect here
    for performance reasons.

    We allow both normal functions and generator functions, though some
    modifier decorators (pass_callback, jsonrpc_immediate) do not
    support generators and will raise a runtime error when a generator
    they decorate is invoked.
    """
    for attribute_name in dir(obj):
        attr = getattr(obj, attribute_name)
        # If it quacks like a function...
        if hasattr(attr, '__call__') and getattr(attr, fn_attrs.jsonrpc, False):
            priv_level = getattr(attr, fn_attrs.priv_level, 0)
            if priv is None or priv_level <= priv:
                exported_name = attribute_name
                jsonrpc.addmethod(exported_name, attr)
        # If priv is a valid level, we set it
        # TODO: When we get more stable, the fcgi server should be refactored so
        # we can remove this priv=None kwarg
        if priv:
            jsonrpc.priv_level = priv

def _gen_once(generator):
    """
    We have several generator methods which are sometimes invoked when there
    is no context in which to iterate them.  For example, we support methods
    which are generators, but if a method is decorated with jsonrpc_immediate,
    we cannot yield out of the invoking function.  This is always a programmer
    error, so we don't want to silently iterate through the generator.  Instead
    we iterate the generator, but raise a runtime error if it actually yields.
    """
    try:
        next(generator)
    except StopIteration as e:
        return e.value
    else:
        raise RuntimeError("Generator has no appropriate context")

class JsonRpcException(Exception):
    def __init__(self, code, message, data=None):
        Exception.__init__(self, code, message)
        self.code = code
        self.message = message
        self.data = data

    def __str__(self):
        return "Code: %s, Message: %s, Data: %s"%(self.code, self.message,
            self.data)

def exc_to_error(e):
    """
    When running a pass_callback method and a JsonRpcException e is raised,
    call callback(error=kaiten.jsonrpc.exc_to_error(e))
    """
    error = { 'code': e.code, 'message': e.message }
    if None is not e.data:
        error['data'] = e.data
    return error

class JsonRpc(object):
    """ JsonRpc handles a json stream, to guarantee the output file pointer
    gets entire valid JSON blocks of data to process, by buffering up data
    into complete blocks and only passing on entire JSON blocks
    """
    def __init__(self, connection, callback,
                 analytics_callback=None,
                 secure=False, tether=False):
        """
        @param connection fileio object.
            Must have .read(), .write(), .stop(), .close()
        @param callback takes a generator as input, and should enqueue it for
            iteration whenever connection.write() will not block.
        @param notify specify whether notifications get sent to this client
        """
        self._client = None
        self._idcounter = 0
        self.connection = connection
        self._jsonreader = kaiten.json_reader.JsonReader(self._jsonreaderresp)
        self._log = kaiten.log.getlogger(self)
        self._methods = {}
        self._methodsinfo={}
        self._jobs = {}
        self._id_counter = 0

        self._queue_callback = callback
        self._analytics_callback = analytics_callback
        self._secure = secure
        self._tether = tether
        self._raw_handler = None
        self._transfer_obj = None
        self._ssl_queue = None

    def set_client(self, client):
        """ Set the client object used for pass_client methods """
        self._client = client

    #
    # Common part
    #
    def store_transfer_object(self, obj):
        """
        Store the transfer object associated with this client.

        This is a fairly hacky way to implement transfer cancellation
        from the rest of kaiten. To cancel a transfer we have to call
        a method on the right TransferMethods object, which is stored as the
        self object of the bound methods put_raw, put_term, etc but nowhere
        else... so Kaiten uses this method to store the object, allowing cancel
        """
        self._transfer_obj = obj

    def get_peer_name(self):
        peer_name = self.connection.peer_name()
        # Just the IP address for network clients
        if isinstance(peer_name, tuple):
            peer_name = peer_name[0]
        return peer_name

    def _get_id(self):
        new_id = self._id_counter
        self._id_counter += 1
        return new_id

    def _jsonreaderresp(self, indata):
        """
        Fired off when a complete jsonrpc packet is parsed by the json reader.
        The json blob is marshalled into a python data type and queued for execution
        depending on its structure:
            dict:
                hasID-> handled as request.  The result is sent back to the caller
                noID-> handled as notification.  No result is sent back to the
                    caller (even in the case of an error
            array:
                iterated over.  Aggregate of results (if components are requests)
                    are stored and sent back to the caller
        The different "handle" function calls return dicts for their response.
        Typically requests are queued for later execution, so the response is
        None.  But parsing errors or "immediate" requests return a dict, which
        is then queued for sending.
        """
        #self._log.debug('(%d)indata=%r', self.connection.fileno(), indata)
        self._packet_count += 1
        if self._packet_count > kaiten.constants.client_packet_limit:
            log_name = self._client.get_log_name() if self._client else 'null'
            self._log.error("Dropping client %s due to excessive packet rate",
                            log_name)
            self.connection.close()
            raise IOError(errno.EMSGSIZE)
        try:
            parsed = json.loads(indata)
        except ValueError:
            response = self._parse_error()
        else:
            if isinstance(parsed, dict):
                # This is checked here and not in handle_object, since arrays
                # are not supposed to have responses in them and we DONT want
                # to support that.
                if self._is_response(parsed):
                    # Currently we do not support "immediate" reponses
                    self._queue_callback(self._handle_response(parsed))
                    # We return here, since theres no more work to be done
                    return
                else:
                    response = self._handle_object(parsed)
            elif isinstance(parsed, list):
                response = yield from self._handle_array(parsed)
            else:
                response = self._invalid_request(None)
        if None is not response:
            #self._log.debug('response=%r', response)
            outdata = json.dumps(response)
            self._queue_callback(self._send(outdata))

    def _handle_object(self, parsed):
        """
        Handles a parsed object.  Depending on the contents of the parsed dict,
        it will either invoke it as a notification or as a request.  Depending
        on the method, this will either directly execute the function or queue
        it for later execution.
        """
        # We check is parsed is a dict again here to support _handle_array
        if not isinstance(parsed, dict):
            return self._invalid_request(None)
        else:
            is_request = self._is_request(parsed)
            is_notification = self._is_notification(parsed)
            if is_request or is_notification:
                method = parsed["method"]
                if method in self._methods:
                    func = self._methods[method]
                    req_secure = getattr(func, fn_attrs.require_secure, False)
                    req_tether = getattr(func, fn_attrs.require_tether, False)
                    if (req_secure and not self._secure)\
                       or (req_tether and not self._tether):
                        if not is_request: return
                        return self._unsecure_error(parsed.get("id"))
                    elif not getattr(func, fn_attrs.jsonrpc_immediate, False):
                        handler = self._queued_handle_object(parsed, is_request)
                        self._queue_callback(handler)
                    elif is_request:
                        return _gen_once(self._handle_request(parsed))
                    else:
                        _gen_once(self._handle_notification(parsed))
                elif is_request:
                    return self._method_not_found(parsed.get("id"))
            else:
                return self._invalid_request(parsed.get("id"))

    def _queued_handle_object(self, parsed, is_request):
        """
        Same as _handle_object, but always directly execute a method, and
        directly send any responses.  The request is not error checked here.
        """
        if is_request:
            response = yield from self._handle_request(parsed)
            if None is not response:
                #self._log.debug('response=%r', response)
                outdata = json.dumps(response)
                yield from self._send(outdata)
        else:
            yield from self._handle_notification(parsed)

    def _handle_array(self, parsed):
        """
        Executes several RPC calls, appending each result to a list and returning
        those results.  Notifications ARE NOT appended to the results list.
        """
        if 0 == len(parsed):
            return self._invalid_request(None)
        else:
            response = []
            for subparsed in parsed:
                subresponse = self._handle_object(subparsed)
                yield subresponse
                if None is not subresponse:
                    response.append(subresponse)
            # The server must not response with an empty list
            if len(response) == 0:
                return None
            return response

    def _handle_response(self, parsed):
        """
        Handles a response.  We assume the parsed blob is correctly formatted.
        We fire off the callback passed in during the self.request call.  We
        support both generators and function calls.
        """
        #self._log.debug("Handling response %r", parsed)
        if parsed['id'] in self._jobs:
            response_blob = {}
            if 'error' in parsed:
                response_blob['error'] = parsed['error']
            else:
                response_blob['result'] = parsed['result']
            res = self._jobs[parsed['id']](response_blob)
            if hasattr(res, '__next__'):
                yield from res
            self._jobs.pop(parsed['id'])
        else:
            pass #self._log.debug("Response not in jobs dict: %r", parsed)

    def _is_request(self, parsed):
        """
        Determines if this dict is a request.  Requests have an ID field, and
        are expected to return some sort of result.
        """
        result = (
            'jsonrpc' in parsed
            and '2.0' == parsed['jsonrpc']
            and 'method' in parsed
            and isinstance(parsed['method'], str)
            and 'id' in parsed)
        return result

    def _is_notification(self, parsed):
        """
        Determines if this dict is a notification. Notifications are the same
        as requests, except that they do not have an 'ID' field
        """
        result = (
            'jsonrpc' in parsed
            and '2.0' == parsed['jsonrpc']
            and 'method' in parsed
            and isinstance(parsed['method'], str)
            and 'id' not in parsed)
        return result

    def _is_response(self, parsed):
        """
        Determines if this dict is a response to a previously sent message.
        """
        result = (self._is_success_response(parsed)
            or self._is_error_response(parsed))
        return result

    def _is_success_response(self, parsed):
        """
        Success responses have a result and no error, and the ID of the calling
        RPC
        """
        result = (
            'jsonrpc' in parsed and parsed['jsonrpc'] == "2.0" and 'id' in parsed
            and 'error' not in parsed and 'result' in parsed)
        return result

    def _is_error_response(self, parsed):
        """
        Error responses have an error and no result, and the ID of the calling
        RPC
        """
        result = (
            'jsonrpc' in parsed and parsed['jsonrpc'] == "2.0" and 'id' in parsed
            and 'error' in parsed and 'result' not in parsed)
        return result

    def _success_response(self, id, result):
        response = {'jsonrpc': '2.0', 'result': result, 'id': id}
        return response

    def _errorresponse(self, id, code, message, data=None):
        error = {'code': code, 'message': message}
        if None is not data:
            error['data'] = data
        response = {'jsonrpc': '2.0', 'error': error, 'id': id}
        return response

    def _parse_error(self):
        response = self._errorresponse(None, -32700, 'parse error')
        return response

    def _invalid_request(self, id):
        response = self._errorresponse(id, -32600, 'invalid request')
        return response

    def _method_not_found(self, id):
        response = self._errorresponse(id, -32601, 'method not found')
        return response

    def _invalid_params(self, id):
        response = self._errorresponse(id, -32602, 'invalid params')
        return response

    def _unsecure_error(self, id):
        response = self._errorresponse(
            id, -32604, 'privileged information on unsecure channel')
        return response

    def _send(self, data, extra=None):
        #self._log.info('(%d)data=%r, %r', self.connection.fileno(),
        #               data, len(extra) if extra else None)
        data = bytes(data, 'utf-8')
        try:
            if None is not extra:
                yield from self.connection.write(data, extra)
            else:
                yield from self.connection.write(data)
        except kaiten.error.ConnectionWriteException:
            # The current connection is gone, clean up
            if self._raw_handler is not None:
                self._raw_handler.close()
                self._raw_handler = None

    def feed(self, data):
        """
        Feed a chunk of data to either to the main json parser or a custom raw
        data parser.  Every time the json parser yields we check if there is a
        custom parser; the custom parser is done as soon as it yields data.
        """
        self._packet_count = 0
        while data:
            if None is self._raw_handler:
                for index in self._jsonreader.feed(data):
                    if None is not self._raw_handler:
                        data = data[index:]
                        break
                else:
                    return
            else:
                try:
                    data = self._raw_handler.send(data)
                    if data:
                        self._raw_handler.close()
                        self._raw_handler = None
                except StopIteration:
                    self._raw_handler = None
                    return

    def run(self):
        if self._ssl_queue is not None:
            yield from self._ssl_run()
            return
        while True:
            data = self.connection.read()
            #self._log.info('(%d)Rcvd %r', self.connection.fileno(), data)
            if data == b'': # EOF (dropped connection)
                break
            if None is not data: # None -> EWOULDBLOCK
                self.feed(data)
            yield

    def set_ssl(self, queue):
        """
        Indicate that this connection uses an ssl socket.

        Must be invoked before run()

        @param queue: The send queue for the connection, see _ssl_run.
        """
        self._ssl_queue = queue

    def _ssl_run(self):
        """
        Horribly hacky way to deal with an ssl connection

        Basically whether the file descriptor is blocked on reading
        or writing is mostly independent of whether we are trying to
        read or write to the socket.  And we may still have data to
        read even when the fd is not readable.

        We never want to yield out of this unless we can ensure that
        we will be iterated again if there is data available on the
        connection.  If our fd polls as readable or our last attempt
        to read raised SSLWantReadError, then we know we can safely
        yield out of this.  Otherwise we want to make sure that the
        send queue will iterate us when the socket is writable.  We
        cannot actually put ourselves into the queue though, because
        we cannot enforce a particular order between reads and writes.
        So we use the terrible set_callback mechanism that we already
        added to the GeneratorQueue for usb timeouts.

        We do not attempt to iterate the send queue here, even when
        sending blocks on read, because it would interact poorly with
        the aforementioned mechanism.
        """
        while True:
            self._ssl_read_and_feed()
            yield

    def _ssl_read_and_feed(self):
        """ See _ssl_run (Run, ssl!  Run!) """
        self._ssl_queue.set_callback(None)

        try:
            data = self.connection.read()
        except ssl.SSLWantReadError:
            return
        except ssl.SSLWantWriteError:
            data = None
        # TODO: Do we need to handle dropped connections?
        if data:
            self.feed(data)
        if self._can_read():
            return

        # Ensure that this gets called again when fd is writable
        if not len(self._ssl_queue):
            def cb(): yield
            self._queue_callback(cb())
        self._ssl_queue.set_callback(self._ssl_read_and_feed)

    def _can_read(self):
        """ Return whether our underlying file descriptor is readable """
        fileno = self.connection.fileno()
        return bool(select.select((fileno,), (), (), 0)[0])

    def close(self):
        try:
            self.connection.close()
        except Exception as e:
            pass #self._log.debug('handled exception', exc_info=True)

    #
    # Client part
    #

    def notify(self, method, params, extra=None):
        """
        Sends a notification to a connected client.

        @param method: The method to be called on the client
        @param params: A dict of parameters (param arrays are discouraged)
        @param extra: This can contain an extra byte array which will be sent
            directly over the connection immediately after the notification.
        """
        #self._log.debug('method=%r, params=%r', method, params)
        request = {'jsonrpc': '2.0', 'method': method, 'params': params}
        data = json.dumps(request)
        yield from self._send(data, extra)

    def request(self, method, params, result_callback, extra=None):
        """
        Sends a request to a connected client.

        @param method: The method to be called on the client
        @param params: A dict of parameters (param arrays are discouraged)
        @param request_callback: Invoked if and when the client responds with
            the full response dict as a single argument.  The callback can also
            be a generator, in which case it is iterated completely.  Directly
            yielding from a request inside the callback is kosher iff the
            request is made to the same client who sent the response.
        @param extra: This can contain an extra byte array which will be sent
            directly over the connection immediately after the request.
        """
        #self._log.debug("method=%r, params=%r", method, params)
        _id = self._get_id()
        request = {'jsonrpc': '2.0', 'method': method, 'params': params, 'id': _id}
        data = json.dumps(request)
        self._jobs[_id] = result_callback
        yield from self._send(data, extra)

    def set_raw_handler(self, generator):
        """
        Replace the json packet parser with a custom generator.  This can only
        be called safely when the other end of this connection is blocked from
        sending anything until it receives something from us.
        @param generator: This is fed the incoming data with .send().  Once it
            has received all of the data it needs, it must stop iteration.
            If it instead receives more data than it requires, it must yield
            back the extra data, at which point it will be closed.
        """
        self._raw_handler = generator
        next(self._raw_handler)

    #
    # Server part
    #

    def _get_args_kwargs(self, json_blob):
        """
        Gets the correct args and kwargs from the json_blob and returns them
        """
        if "params" not in json_blob:
            return ((), {})
        elif json_blob['params'] is None:
            return ((), {})
        elif isinstance(json_blob["params"], dict):
            params = json_blob["params"].copy()
            return ((), params)
        elif isinstance(json_blob["params"], list):
            return (json_blob["params"], {})
        else:
            raise AttributeError

    def _handle_notification(self, notification):
        """
        Processes a notification.  Assumes the packet is valid.
        Since its a notification, we catch all errors and do nothing
        with them.  We support generator methods, so this function is
        itself a generator.
        """
        #self._log.debug("notification=%r" % (notification))
        method = notification['method']
        try:
            (args, kwargs) = self._get_args_kwargs(notification)
            func = self._methods[method]
            result = yield from self._invoke_method(func, args, kwargs)
        except Exception as e:
            self._log.error("Error executing notification %r", notification,
                exc_info=True)

    def _handle_request(self, request):
        """
        Handles a request.  Assumes the packet is valid and the method exists.
        Since its a request, we need to handle each error case and return an
        error packet.  We support generator methods, so this function is
        itself a generator.
        """
        _id = request["id"]
        #self._log.debug('request=%r, id=%r', request, _id)
        method = request['method']
        try:
            (args, kwargs) = self._get_args_kwargs(request)
        except AttributeError as e:
            self._log.error('handled exception', exc_info=True)
            return self._invalid_params(_id)
        func = self._methods[method]
        try:
            if getattr(func, fn_attrs.send_analytics, False) and \
                self._analytics_callback and self._client:
                self._analytics_callback(request['method'], self._client)
            if getattr(func, fn_attrs.pass_callback, False):
                self._invoke_callback_method(_id, func, args, kwargs)
                return # Don't send a response, that's the callback's job
            else:
                result = yield from self._invoke_method(func, args, kwargs)
        except TypeError as e:
            self._log.error('handled exception: ' + str(e), exc_info=True)
            response = self._invalid_params(_id)
        except JsonRpcException as e:
            self._log.warning('handled exception', exc_info=True)
            response = self._errorresponse(_id, e.code, e.message, e.data)
        except Exception as e:
            self._log.warning('uncaught exception', exc_info=True)
            e = sys.exc_info()[1]
            data = {'name': e.__class__.__name__, 'args': e.args}
            response = self._errorresponse(
                _id, -32000, 'uncaught exception', data)
        else:
            response = self._success_response(_id, result)
            #self._log.debug('response=%r', result)
        return response

    def _fix_kwargs(self, kwargs):
        kwargs1 = {}
        for k, v in kwargs.items():
            k = str(k)
            kwargs1[k] = v
        return kwargs1

    @staticmethod
    def _check_argument_types(value, _type, param_name):
        """
        Checks argument types and potentially mutates them
        """
        if(isinstance(value, int) and (_type is float)):
            return float(value)
        if type(value) is not _type:
            raise TypeError("Param %s must have type %s" %
                                    (param_name, _type.__name__))
        return value

    @staticmethod
    def _check_types(func, args, kwargs):
        """
        Ensures that args and kwargs match the types annotated by func.
        This calls _check_argument_types which may mutate args/kwargs
        Succeeds or raises TypeError.
        """
        # This is how to examine python internals without using inspect
        # (because the boot hack doesn't like it). This is picked up from
        # https://docs.python.org/3/reference/datamodel.html
        # 1. Callables have an __annotations__ attribute that is a dict of
        # arg names: annotations, for all args that have annotations
        # 2. Callables have a __code__ attribute that is their compile-time
        # defined information, including the argcount and the names of free
        # variables.
        # 3. So to check all args that have annotations, iterate through
        # argcount and use that to look up arg names (the first argcount
        # elements in varnames) and, if the arg isn't self, see if it's
        # in annotations, and, if it is, check it. Easy!
        anns = func.__annotations__
        argc = func.__code__.co_argcount
        vn = func.__code__.co_varnames
        if 'self' in vn:
            # No need to typecheck self for bound methods
            argc -= 1
            vn = vn[1:]
        # If there are unspecified args, they must be specified as kwargs so we
        # have to check them
        check_kwargs = argc > len(args)
        for idx in range(len(args)):
            if idx > len(args):
                check_kwargs = True
                break
            if vn[idx] in anns:
                args[idx] = kaiten.jsonrpc.JsonRpc._check_argument_types(args[idx],
                 anns[vn[idx]], vn[idx])
        if check_kwargs:
            for k in kwargs:
                if k in anns:
                    kwargs[k] = kaiten.jsonrpc.JsonRpc._check_argument_types(kwargs[k], anns[k], k)

    def _invoke_method(self, func, args, kwargs, ignore_result=False):
        """
        Invokes a method.  We support generator methods, so this function is
        itself a generator.
        """

        #this is a method that wants to access the current jsonrpc object
        if getattr(func, fn_attrs.pass_client, False):
            kwargs['client'] = self._client
        kwargs = self._fix_kwargs(kwargs)
        if getattr(func, fn_attrs.enforce_types, False):
            self._check_types(func, args, kwargs)
        result = func(*args, **kwargs)
        if ignore_result: return
        if hasattr(result, '__next__'):
            result = yield from result
        return result

    def _invoke_callback_method(self, _id, func, args, kwargs):
        """
        Invokes a method which will not return a result immediately, but will
        invoke a callback when the result is ready
        """
        def request_callback(result=None, error=None, **kwargs):
            """
            Add generic kwargs that are ignored so that jsonrpc responses can be
            passed straight through with callback(**response)
            """
            try:
                if None is not error:
                    response = self._errorresponse(_id, **error)
                else:
                    response = self._success_response(_id, result)
            except Exception as e:
                self._log.error('Error in request callback', exc_info=True)
                response = self._errorresponse(_id, -32603, 'internal error')
            outdata = json.dumps(response)
            self._queue_callback(self._send(outdata))
        kwargs['callback'] = request_callback
        _gen_once(self._invoke_method(func, args, kwargs, ignore_result=True))

    def addmethod(self, method, func):
        #self._log.debug('method=%r, func=%r', method, func)
        self._methods[method] = func

    def getmethods(self):
        return self._methods

    def cancel_transfer(self, filepath:str):
        """
        Cancel an ongoing file transfer to filepath, if it exists.

        This method also will do nothing if this client was not constructed with
        a kaiten.TransferMethods object.
        """
        if self._transfer_obj:
            self._transfer_obj.cancel(filepath)
        else:
            self._log.warning("Tried to cancel a file transfer on a client"
                              " with no transfer handler!")
