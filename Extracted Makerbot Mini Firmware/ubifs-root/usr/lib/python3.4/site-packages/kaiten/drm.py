import json
import os
import struct
import zipfile
import zlib

import kaiten.log

DRM_CONFIG = {
    # Check if this layout+account combo is already is use?
    "STATUS" : "status",
    # Receive a zip file of all meta data
    "METADATA" : "full_metadata",
    # Tell the host to start at the first packet
    "INITIALIZATION" : "stream",
    # Request the next packet
    "STREAM" : "packet",
    # Tell the server we are done with this layout
    "COMPLETION" : "completion",
    # Retrieve a full, zipped toolpath
    "SINGLE_FILE" : "zipped_toolpath",
    # Supports 'http' or 'https'
    "SCHEME" : "https",
}

# TODO: maybe use this for ziplogsprocess?
class ZipFileGenerator(zipfile.ZipFile):
    """
    Subclass of Zipfile that allows streaming compression
    """
    def write_generator(self, zinfo):
        """
        Generator that accepts bytes objects and places them into
        zip file in accordance with the passed in ZipInfo object.
        Only supports ZIP_DEFLATED compression_type.  Explicitly
        close the generator to finish adding to the file.
        """
        zinfo.header_offset = self.fp.tell()    # Start of header data
        zinfo.file_size = size = 0              # Placeholder values...
        zinfo.compress_size = co_size = 0
        zinfo.CRC = CRC = 0

        self._writecheck(zinfo)
        self._didModify = True
        self.fp.write(zinfo.FileHeader())

        co = zipfile._get_compressor(zinfo.compress_type)

        try:
            while True:
                data = yield
                size += len(data)
                CRC = zipfile.crc32(data, CRC) & 0xffffffff
                data = co.compress(data)
                self.fp.write(data)
                co_size += len(data)

        except GeneratorExit:
            data = co.flush()
            self.fp.write(data)
            self.fp.flush()
            co_size += len(data)

            # Seek backwards and write CRC and file sizes
            position = self.fp.tell()
            self.fp.seek(zinfo.header_offset + 14, 0)
            self.fp.write(struct.pack("<LLL", CRC, co_size, size))
            self.fp.seek(position, 0)

            zinfo.file_size = size
            zinfo.compress_size = co_size
            zinfo.CRC = CRC
            self.filelist.append(zinfo)
            self.NameToInfo[zinfo.filename] = zinfo
            raise

def defer_error(func):
    def decorator(self, *args, **kwargs):
        try:
            return func(self, *args, **kwargs)
        except Exception as e:
            self._log.error('Deferring error', exc_info=True)
            self._error = e
    return decorator

class DRMStore(object):
    def __init__(self, server, host, token, layout_id, path):
        """
        Creates an object that streams a layout from the specified host
        to a local (secure) file path on the bot.

        @param server - The main kaiten server object
        @param host - Remote host to stream the file from
        @param token - A thingiverse access token
        @param layout_id - ID of the layout to stream
        @param path - the file path to stream the object to
        """
        self._server = server
        self._host = host
        self.path = path
        self._token = token
        self._base_params = {
            'access_token' : token,
            'layout_id' : layout_id,
        }
        self._log = kaiten.log.getlogger(self)
        self._packet_number = 0
        self._completed = False
        self._metadata_downloaded = False
        self._error = None
        self._use_https = DRM_CONFIG['SCHEME'] == 'https'
        self._file_handle = None
        self._init_storage()
        self._metadata_path = None
        self._temp_token = None

    def _init_storage(self):
        dir = os.path.dirname(self.path)
        if not os.path.isdir(dir):
            os.makedirs(dir)
        self._zip = ZipFileGenerator(self.path, 'w')
        # Remove this file from the filesystem, but don't close
        # our file pointer so that we can pass the file descriptor
        # around.
        self._file_handle = open(self.path, 'r')
        os.remove(self.path)
        info = zipfile.ZipInfo('print.jsontoolpath')
        info.compress_type = zipfile.ZIP_DEFLATED
        self._gen = self._zip.write_generator(info)
        next(self._gen)

    def fileno(self):
        """
        Returns the file descriptor of the open zip file
        """
        return self._file_handle.fileno()

    def _close_storage(self):
        self._gen.close()
        self._zip.close()

    def close(self):
        # Close the file handle that we keep open for the parser
        self._file_handle.close()

    def _make_request(self, path, params, callback, verb='POST', **kwargs):
        """
        Start an http request to our host, invoke callback if it succeeds

        @param path - Path to request minus the leading /
        @param params - Parameters (besides the base parameters)
        @param callback - Invoked on success with the returned data
        @param verb - 'POST', 'GET', etc.
        @param **kwargs - Any additional arguments for http_request
        """
        full_params = self._base_params.copy()
        full_params.update(params)
        kwargs.setdefault('encoding', 'json')
        self._server.http_request(
            self._host,
            '/' + path,
            verb,
            params=full_params,
            https=self._use_https,
            token=self._token,
            success_callback=callback,
            error_callback=self._handle_error,
            **kwargs
        )

    def _handle_error(self, **kwargs):
        # TODO: better error handling
        self._error = kaiten.error.ThingiverseException

    def get_metadata(self, metadata_path):
        """ Start a request for a binary zip file containing metadata """
        self._metadata_path = metadata_path
        self._make_request(
            DRM_CONFIG['METADATA'],
            {},
            self._handle_metadata,
            bytes_response=True,
        )

    @defer_error
    def _handle_metadata(self, data):
        """ Callback to handle the zipped metadata download """
        with open(self._metadata_path, "wb") as f:
            f.write(data)
        self._metadata_downloaded = True

    def _get_packet(self, temp_token):
        """ Start a request for a single packet """
        self._make_request(
            DRM_CONFIG['STREAM'],
            {'packet_no' : self._packet_number, 'temp_token': temp_token},
            self._handle_packet,
        )

    @defer_error
    def _handle_packet(self, data):
        """ Callback to handle the wrapped packet sent by the server """
        result = json.loads(data)
        temp_token = result['temp_token']
        packet = result['packet']
        if not packet:
            # We have already transferred the entire file
            self._close_storage()
            self._complete_stream(temp_token)
            self._completed = True
        else:
            self._store_packet(packet.encode('ascii'))
            self._packet_number += 1
            self._get_packet(temp_token)

    def _store_packet(self, packet):
        """ Actually store the packet locally """
        self._gen.send(packet)

    def _complete_stream(self, temp_token):
        """ Inform the host that we are done with the layout """
        self._make_request(
            DRM_CONFIG['COMPLETION'],
            {'completion_status' : 0, 'temp_token': temp_token},
            None,
        )

    @defer_error
    def _init_callback(self, data):
        """ Callback to handle the initialization response """
        result = json.loads(data)
        self._temp_token = result['temp_token']
        # We don't currently use result['print_length']
        self._get_packet(self._temp_token)

    def start(self):
        """
        Kick off the chain of IO generators that does the real work.
        """
        printer = self._server._config["kaiten"]["machine_type"],
        self._make_request(
            DRM_CONFIG['INITIALIZATION'],
            {'printer' : printer},
            self._init_callback,
        )

    def clear_error(self):
        """ Clear any deferred errors """
        self._error = None

    def check_error(self):
        """ If any error occured, raise it """
        if self._error:
            raise self._error # pylint: disable=raising-bad-type

    def completed(self):
        """
        Check if we completed our transfer.
        If we had an error, raise it.
        """
        self.check_error()
        return self._completed

    def metadata_downloaded(self):
        """
        Checks if metadata file is downloaded.
        If we had an error, raise it.
        """
        self.check_error()
        return self._metadata_downloaded

    def _get_completion_callback(self, callback):
        def _completion_callback(data):
            self._log.info("Streaming print completion status response: {0}".format(data))
            try:
                if callback is not None:
                    result = json.loads(data)
                    callback(result)
            except Exception as e:
                self._log.error('Deferring error', exc_info=True)
                self._error = e
        return _completion_callback

    def send_completion(self, cancelled, failed, callback=None):
        """
        Send an update to the streaming server
        """
        if failed:
            completion_status = 2
        elif cancelled:
            completion_status = 1
        else:
            completion_status = 0
        params = {
            "temp_token" : self._temp_token,
            "completion_status" : completion_status
        }
        self._log.info("Sending streaming print completion: {0}".format(completion_status))
        self._make_request(
            DRM_CONFIG['COMPLETION'],
            params,
            self._get_completion_callback(callback)
        )

class DRMStoreV2(DRMStore):
    def _init_storage(self):
        dir = os.path.dirname(self.path)
        if not os.path.isdir(dir):
            os.makedirs(dir)
        self._writer = open(self.path, 'wb')
        # Remove this file from the filesystem, but keep a second
        # file pointer open for reading so that we can still retrieve
        # the data.
        self._file_handle = open(self.path, 'r')
        os.remove(self.path)

    def _close_storage(self):
        self._writer.close()

    @defer_error
    def _single_file_callback(self, dummy):
        """ Callback invoked when the file is completed """
        self._writer.flush()
        self._completed = True

    def start(self):
        """
        Kick off the IO generator that does the real work.
        """
        printer = self._server._config["kaiten"]["machine_type"]
        # Get the temp token to use for completion status later
        self._make_request(
            DRM_CONFIG['INITIALIZATION'],
            {'printer' : printer},
            self._init_callback,
        )
        # Start the download
        self._make_request(
            DRM_CONFIG['SINGLE_FILE'],
            {},
            self._single_file_callback,
            file_response = self._writer,
        )

    @defer_error
    def _init_callback(self, data):
        """ Callback to handle the initialization response """
        result = json.loads(data)
        self._temp_token = result['temp_token']

